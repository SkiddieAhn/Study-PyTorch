{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GANomaly Architecture\n",
    "<hr/> \n",
    "\n",
    "##### If the resolution increases, the network is also increased!\n",
    "\n",
    "ex.1) resolution(width,height): 64 -> parameter(MB): 40MB  \n",
    "ex.2) resolution(width,height): 128 -> parameter(MB): 140MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Yaktocat](https://raw.githubusercontent.com/openvinotoolkit/anomalib/main/docs/source/images/ganomaly/architecture.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<< Important Formula >>\n",
    "\n",
    "- Convolution Shape Formula: (n+2p-f)/s + 1\n",
    "- Deconvolution Shape Formula: s(n-1)+f-2p\n",
    "\n",
    "* n: input size\n",
    "* p: padding\n",
    "* s: stride\n",
    "* f: kernel size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GANomaly Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, isize, icnl, z_length):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        isize: input_size, icnl: input_channel \n",
    "        fsize: feature_size, fcnl: feature_channel\n",
    "        z_length: latent vector z length \n",
    "        \"isize has to be a 16 x 2^i (i>0)\n",
    "         ex) 16, 32, 64, 128, 256, ...\"\n",
    "         \n",
    "        \"\"\"\n",
    "        def CBLR2d(in_channels,out_channels,kernel_size,stride=1,padding=0,bias=True,batchnorm=True):\n",
    "            layers=[]\n",
    "            layers+=[nn.Conv2d(in_channels=in_channels,out_channels=out_channels,\n",
    "            kernel_size=kernel_size,stride=stride,padding=padding,bias=bias)]\n",
    "            if batchnorm:\n",
    "                layers+=[nn.BatchNorm2d(num_features=out_channels)]\n",
    "            layers+=[nn.LeakyReLU(0.2, inplace=True)]\n",
    "            conv=nn.Sequential(*layers)\n",
    "            return conv\n",
    "\n",
    "        # make layers\n",
    "        layers=nn.Sequential()\n",
    "        layer_num=0\n",
    "\n",
    "        # first layer\n",
    "        # (icnl x isize x isize) -> (fcnl x fsize x fsize) // fcnl =64, fsize = isize / 2\n",
    "        layers.add_module('layer_{}'.format(layer_num),\n",
    "        CBLR2d(in_channels=icnl, out_channels=64, kernel_size=4, stride=2, padding=1, bias=False, batchnorm=False))\n",
    "        fsize, fcnl = isize/2, 64\n",
    "        layer_num+=1\n",
    "\n",
    "        # other layers\n",
    "        # (fcnl x fsize x fsize) -> (fcnl*2 x fsize/2 x fsize/2) until fsize become 4\n",
    "        while fsize > 4:\n",
    "            layers.add_module('layer_{}'.format(layer_num),\n",
    "            CBLR2d(in_channels=fcnl, out_channels=fcnl*2, kernel_size=4, stride=2, padding=1, bias=False))\n",
    "            fsize = fsize/2\n",
    "            fcnl = fcnl*2\n",
    "            layer_num+=1\n",
    "        \n",
    "        # last layer\n",
    "        # (fcnl x 4 x 4) -> (z_length x 1 x 1) \n",
    "        layers.add_module('layer_{}'.format(layer_num),\n",
    "        nn.Conv2d(in_channels=fcnl, out_channels=z_length, kernel_size=4, stride=1, padding=0, bias=False))\n",
    "        \n",
    "        self.layers=layers\n",
    "\n",
    "    def forward(self,x):\n",
    "        output=self.layers(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GANomaly Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, osize, ocnl, z_length):\n",
    "        super().__init__()\n",
    "        \n",
    "        \"\"\"\n",
    "        osize: output_size, ocnl: output_channel \n",
    "        k: (number of convolution in encoder)-1\n",
    "        fsize: feature_size, fcnl: feature_channel\n",
    "        z_length: latent vector z length \n",
    "        \"osize has to be a 16 x 2^i (i>0)\n",
    "         ex) 16, 32, 64, 128, 256, ...\"\n",
    "\n",
    "        \"\"\"\n",
    "        def CTBR2d(in_channels,out_channels,kernel_size,stride=1,padding=0,bias=True,batchnorm=True):\n",
    "            layers=[]\n",
    "            layers+=[nn.ConvTranspose2d(in_channels=in_channels,out_channels=out_channels,\n",
    "            kernel_size=kernel_size,stride=stride,padding=padding,bias=bias)]\n",
    "            if batchnorm:\n",
    "                layers+=[nn.BatchNorm2d(num_features=out_channels)]\n",
    "            layers+=[nn.ReLU(inplace=True)]\n",
    "            convT=nn.Sequential(*layers)\n",
    "            return convT\n",
    "        \n",
    "        # make layers\n",
    "        layers=nn.Sequential()\n",
    "        layer_num=0\n",
    "\n",
    "        # first layer\n",
    "        # (z_length x 1 x 1) -> (64*{2^(k-1)} x 4 x 4) // k=log2(osize/4) \n",
    "        k = int(np.log2(osize/4))\n",
    "        out = int(64 * np.power(2,k-1))\n",
    "        layers.add_module('layer_{}'.format(layer_num),\n",
    "        CTBR2d(in_channels=z_length, out_channels=out, kernel_size=4, stride=1, padding=0, bias=False))\n",
    "        fsize, fcnl = 4, out\n",
    "        layer_num+=1\n",
    "\n",
    "        # other layers\n",
    "        # (fcnl x fsize x fsize) -> (fcnl/2 x fsize*2 x fsize*2) until fsize become osize/2\n",
    "        while fsize < (osize // 2):\n",
    "            layers.add_module('layer_{}'.format(layer_num),\n",
    "            CTBR2d(in_channels=fcnl, out_channels=fcnl//2, kernel_size=4, stride=2, padding=1, bias=False))\n",
    "            fsize = fsize*2\n",
    "            fcnl = fcnl//2\n",
    "            layer_num+=1\n",
    "\n",
    "        # last layer\n",
    "        # (fcnl x osize/2 x osize/2) -> (ocnl x osize x osize) \n",
    "        layer=[]\n",
    "        layer+=[nn.ConvTranspose2d(in_channels=fcnl,out_channels=ocnl,kernel_size=4,stride=2,padding=1,bias=False)]\n",
    "        layer+=[nn.Tanh()]\n",
    "        last_layer=nn.Sequential(*layer)\n",
    "        layers.add_module('layer_{}'.format(layer_num),last_layer)\n",
    "\n",
    "        self.layers=layers\n",
    "\n",
    "    def forward(self,x):\n",
    "        output=self.layers(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show Encoder \n",
    "\n",
    "(3x64x64 -> 100x1x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           3,072\n",
      "         LeakyReLU-2           [-1, 64, 32, 32]               0\n",
      "            Conv2d-3          [-1, 128, 16, 16]         131,072\n",
      "       BatchNorm2d-4          [-1, 128, 16, 16]             256\n",
      "         LeakyReLU-5          [-1, 128, 16, 16]               0\n",
      "            Conv2d-6            [-1, 256, 8, 8]         524,288\n",
      "       BatchNorm2d-7            [-1, 256, 8, 8]             512\n",
      "         LeakyReLU-8            [-1, 256, 8, 8]               0\n",
      "            Conv2d-9            [-1, 512, 4, 4]       2,097,152\n",
      "      BatchNorm2d-10            [-1, 512, 4, 4]           1,024\n",
      "        LeakyReLU-11            [-1, 512, 4, 4]               0\n",
      "           Conv2d-12            [-1, 100, 1, 1]         819,200\n",
      "================================================================\n",
      "Total params: 3,576,576\n",
      "Trainable params: 3,576,576\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 2.31\n",
      "Params size (MB): 13.64\n",
      "Estimated Total Size (MB): 16.00\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "<bound method Module.parameters of Encoder(\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (layer_1): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (layer_2): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (layer_3): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (layer_4): Conv2d(512, 100, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "model=Encoder(isize=64, icnl= 3, z_length=100).to(device)\n",
    "print(summary(model,(3,64,64)))\n",
    "print(model.parameters)\n",
    "# Input Shape: [-1, 3, 64, 64]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show Decoder\n",
    "\n",
    "(100x1x1 -> 3x64x64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1            [-1, 512, 4, 4]         819,200\n",
      "       BatchNorm2d-2            [-1, 512, 4, 4]           1,024\n",
      "              ReLU-3            [-1, 512, 4, 4]               0\n",
      "   ConvTranspose2d-4            [-1, 256, 8, 8]       2,097,152\n",
      "       BatchNorm2d-5            [-1, 256, 8, 8]             512\n",
      "              ReLU-6            [-1, 256, 8, 8]               0\n",
      "   ConvTranspose2d-7          [-1, 128, 16, 16]         524,288\n",
      "       BatchNorm2d-8          [-1, 128, 16, 16]             256\n",
      "              ReLU-9          [-1, 128, 16, 16]               0\n",
      "  ConvTranspose2d-10           [-1, 64, 32, 32]         131,072\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      "             ReLU-12           [-1, 64, 32, 32]               0\n",
      "  ConvTranspose2d-13            [-1, 3, 64, 64]           3,072\n",
      "             Tanh-14            [-1, 3, 64, 64]               0\n",
      "================================================================\n",
      "Total params: 3,576,704\n",
      "Trainable params: 3,576,704\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 3.00\n",
      "Params size (MB): 13.64\n",
      "Estimated Total Size (MB): 16.64\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "<bound method Module.parameters of Decoder(\n",
      "  (layers): Sequential(\n",
      "    (layer_0): Sequential(\n",
      "      (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (layer_1): Sequential(\n",
      "      (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (layer_2): Sequential(\n",
      "      (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (layer_3): Sequential(\n",
      "      (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (layer_4): Sequential(\n",
      "      (0): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "model=Decoder(osize=64, ocnl= 3, z_length=100).to(device)\n",
    "print(summary(model,(100,1,1)))\n",
    "print(model.parameters)\n",
    "# Input Shape: [-1, 100, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Generator & Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetG(nn.Module):\n",
    "    \"\"\"\n",
    "    GENERATOR & ENCODER NETWORK\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, setting):\n",
    "        super(NetG, self).__init__()\n",
    "        self.encoder1 = Encoder(isize=setting.isize, icnl= setting.icnl, z_length=setting.z_length)\n",
    "        self.decoder = Decoder(osize=setting.isize, ocnl= setting.icnl, z_length=setting.z_length)\n",
    "        self.encoder2 = Encoder(isize=setting.isize, icnl= setting.icnl, z_length=setting.z_length)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder1(x)\n",
    "        fake = self.decoder(z)\n",
    "        z_carat = self.encoder2(fake)\n",
    "        return fake, z, z_carat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetD(nn.Module):\n",
    "    \"\"\"\n",
    "    DISCRIMINATOR NETWORK\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, setting):\n",
    "        super(NetD, self).__init__()\n",
    "        model = Encoder(isize=setting.isize, icnl= setting.icnl, z_length=1) # one class classification\n",
    "        layers = list(model.layers.children())\n",
    "\n",
    "        self.features = nn.Sequential(*layers[:-1])\n",
    "        self.classifier = nn.Sequential(layers[-1])\n",
    "        self.classifier.add_module('Sigmoid', nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.features(x)\n",
    "        classifier = self.classifier(features)\n",
    "        classifier = classifier.view(-1, 1).squeeze(1)\n",
    "\n",
    "        return classifier, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class setting:\n",
    "    \"\"\"\n",
    "    isize: input_size <isize has to be a 16 x 2^i (i>0)>\n",
    "    icnl: input_channel \n",
    "    z_length: latent vector z length \n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,isize,icnl,z_length):\n",
    "        self.isize=isize\n",
    "        self.icnl=icnl\n",
    "        self.z_length=z_length\n",
    "    \n",
    "    def show(self):\n",
    "        print('isize:',self.isize)\n",
    "        print('icnl:',self.icnl)\n",
    "        print('z_length:',self.z_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isize: 64\n",
      "icnl: 3\n",
      "z_length: 100\n"
     ]
    }
   ],
   "source": [
    "my_setting=setting(isize=64,icnl=3,z_length=100)\n",
    "my_setting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show Generator & Encoder\n",
    "\n",
    "(3x64x64 -> 100x1x1 -> 3x64x64 -> 100x1x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           3,072\n",
      "         LeakyReLU-2           [-1, 64, 32, 32]               0\n",
      "            Conv2d-3          [-1, 128, 16, 16]         131,072\n",
      "       BatchNorm2d-4          [-1, 128, 16, 16]             256\n",
      "         LeakyReLU-5          [-1, 128, 16, 16]               0\n",
      "            Conv2d-6            [-1, 256, 8, 8]         524,288\n",
      "       BatchNorm2d-7            [-1, 256, 8, 8]             512\n",
      "         LeakyReLU-8            [-1, 256, 8, 8]               0\n",
      "            Conv2d-9            [-1, 512, 4, 4]       2,097,152\n",
      "      BatchNorm2d-10            [-1, 512, 4, 4]           1,024\n",
      "        LeakyReLU-11            [-1, 512, 4, 4]               0\n",
      "           Conv2d-12            [-1, 100, 1, 1]         819,200\n",
      "          Encoder-13            [-1, 100, 1, 1]               0\n",
      "  ConvTranspose2d-14            [-1, 512, 4, 4]         819,200\n",
      "      BatchNorm2d-15            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-16            [-1, 512, 4, 4]               0\n",
      "  ConvTranspose2d-17            [-1, 256, 8, 8]       2,097,152\n",
      "      BatchNorm2d-18            [-1, 256, 8, 8]             512\n",
      "             ReLU-19            [-1, 256, 8, 8]               0\n",
      "  ConvTranspose2d-20          [-1, 128, 16, 16]         524,288\n",
      "      BatchNorm2d-21          [-1, 128, 16, 16]             256\n",
      "             ReLU-22          [-1, 128, 16, 16]               0\n",
      "  ConvTranspose2d-23           [-1, 64, 32, 32]         131,072\n",
      "      BatchNorm2d-24           [-1, 64, 32, 32]             128\n",
      "             ReLU-25           [-1, 64, 32, 32]               0\n",
      "  ConvTranspose2d-26            [-1, 3, 64, 64]           3,072\n",
      "             Tanh-27            [-1, 3, 64, 64]               0\n",
      "          Decoder-28            [-1, 3, 64, 64]               0\n",
      "           Conv2d-29           [-1, 64, 32, 32]           3,072\n",
      "        LeakyReLU-30           [-1, 64, 32, 32]               0\n",
      "           Conv2d-31          [-1, 128, 16, 16]         131,072\n",
      "      BatchNorm2d-32          [-1, 128, 16, 16]             256\n",
      "        LeakyReLU-33          [-1, 128, 16, 16]               0\n",
      "           Conv2d-34            [-1, 256, 8, 8]         524,288\n",
      "      BatchNorm2d-35            [-1, 256, 8, 8]             512\n",
      "        LeakyReLU-36            [-1, 256, 8, 8]               0\n",
      "           Conv2d-37            [-1, 512, 4, 4]       2,097,152\n",
      "      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n",
      "        LeakyReLU-39            [-1, 512, 4, 4]               0\n",
      "           Conv2d-40            [-1, 100, 1, 1]         819,200\n",
      "          Encoder-41            [-1, 100, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 10,729,856\n",
      "Trainable params: 10,729,856\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 7.72\n",
      "Params size (MB): 40.93\n",
      "Estimated Total Size (MB): 48.70\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "<bound method Module.parameters of NetG(\n",
      "  (encoder1): Encoder(\n",
      "    (layers): Sequential(\n",
      "      (layer_0): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      )\n",
      "      (layer_1): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      )\n",
      "      (layer_2): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      )\n",
      "      (layer_3): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      )\n",
      "      (layer_4): Conv2d(512, 100, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (layers): Sequential(\n",
      "      (layer_0): Sequential(\n",
      "        (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (layer_1): Sequential(\n",
      "        (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (layer_2): Sequential(\n",
      "        (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (layer_3): Sequential(\n",
      "        (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (layer_4): Sequential(\n",
      "        (0): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder2): Encoder(\n",
      "    (layers): Sequential(\n",
      "      (layer_0): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      )\n",
      "      (layer_1): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      )\n",
      "      (layer_2): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      )\n",
      "      (layer_3): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      )\n",
      "      (layer_4): Conv2d(512, 100, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "model=NetG(my_setting).to(device)\n",
    "print(summary(model,(3,64,64)))\n",
    "print(model.parameters)\n",
    "# start: [-1, 3, 64, 64]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show Discriminator\n",
    "\n",
    "(3x64x64 -> 1x1x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           3,072\n",
      "         LeakyReLU-2           [-1, 64, 32, 32]               0\n",
      "            Conv2d-3          [-1, 128, 16, 16]         131,072\n",
      "       BatchNorm2d-4          [-1, 128, 16, 16]             256\n",
      "         LeakyReLU-5          [-1, 128, 16, 16]               0\n",
      "            Conv2d-6            [-1, 256, 8, 8]         524,288\n",
      "       BatchNorm2d-7            [-1, 256, 8, 8]             512\n",
      "         LeakyReLU-8            [-1, 256, 8, 8]               0\n",
      "            Conv2d-9            [-1, 512, 4, 4]       2,097,152\n",
      "      BatchNorm2d-10            [-1, 512, 4, 4]           1,024\n",
      "        LeakyReLU-11            [-1, 512, 4, 4]               0\n",
      "           Conv2d-12              [-1, 1, 1, 1]           8,192\n",
      "          Sigmoid-13              [-1, 1, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 2,765,568\n",
      "Trainable params: 2,765,568\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 2.31\n",
      "Params size (MB): 10.55\n",
      "Estimated Total Size (MB): 12.91\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "<bound method Module.parameters of NetD(\n",
      "  (features): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (Sigmoid): Sigmoid()\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "model=NetD(my_setting).to(device)\n",
    "print(summary(model,(3,64,64)))\n",
    "print(model.parameters)\n",
    "# Input Shape: [-1, 3, 64, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
