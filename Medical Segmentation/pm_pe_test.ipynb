{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, einsum\n",
    "from einops import rearrange\n",
    "from pytorch_model_summary import summary\n",
    "from monai.networks.layers.utils import get_norm_layer\n",
    "from unetr_plus_plus.unetr_pp.network_architecture.dynunet_block import get_conv_layer, UnetResBlock\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "patch merging 테스트 (embedding 없이)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchMerging(nn.Module):\n",
    "    def __init__(self, dim, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        # self.norm = norm_layer(8 * dim)\n",
    "        # self.reduction = nn.Linear(8 * dim, 2 * dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: B,C,D,H,W\n",
    "        \"\"\"\n",
    "        x=x.permute(0,3,4,2,1) # [B,H,W,D,C]\n",
    "        B=x.shape[0];H=x.shape[1];W=x.shape[2];D=x.shape[3];C=x.shape[4]\n",
    "\n",
    "        y=None\n",
    "        for i in range(0,D,2):\n",
    "            # process 2 slice\n",
    "            x_=x[:, :, :, i:i+2, :] # B, H/2, W/2, 2, C\n",
    "            \n",
    "            x_0=x_[:, 0::2, 0::2, :, :] # B, H/2, W/2, 2, C\n",
    "            x_1=x_[:, 0::2, 1::2, :, :] # B, H/2, W/2, 2, C \n",
    "            x_2=x_[:, 1::2, 0::2, :, :]  # B, H/2, W/2, 2, C \n",
    "            x_3=x_[:, 1::2, 1::2, :, :] # B, H/2, W/2, 2, C\n",
    "\n",
    "            # width, height information -> channel information\n",
    "            rst=torch.cat([x_0,x_1,x_2,x_3],-1) # B, H/2, W/2, 2, 4*C\n",
    "\n",
    "            # dimension information -> channel information\n",
    "            rst=rst.view(B, H//2, W//2, 1, 8*C) # B, H/2, W/2, 1, 8*C\n",
    "\n",
    "            # concat \n",
    "            if i==0:\n",
    "                y=rst.clone() # B, H/2, W/2, 1, 8*C\n",
    "            else:\n",
    "                y=torch.cat([y,rst],-2) # final shape -> [B, H/2, W/2, D/2, 8*C]\n",
    "        \n",
    "        # # normalization\n",
    "        # y=self.norm(y) # B, H/2, W/2, D/2, 8*C\n",
    "        \n",
    "        # # embedding\n",
    "        # y=self.reduction(y) # B, H/2, W/2, D/2, 2*C\n",
    "\n",
    "        y=y.permute(0,4,3,1,2) # B, 2*C, D/2, H/2, W/2\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "tensor([[[ 1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8],\n",
      "         [ 9, 10, 11, 12],\n",
      "         [13, 14, 15, 16]],\n",
      "\n",
      "        [[17, 18, 19, 20],\n",
      "         [21, 22, 23, 24],\n",
      "         [25, 26, 27, 28],\n",
      "         [29, 30, 31, 32]],\n",
      "\n",
      "        [[33, 34, 35, 36],\n",
      "         [37, 38, 39, 40],\n",
      "         [41, 42, 43, 44],\n",
      "         [45, 46, 47, 48]],\n",
      "\n",
      "        [[49, 50, 51, 52],\n",
      "         [53, 54, 55, 56],\n",
      "         [57, 58, 59, 60],\n",
      "         [61, 62, 63, 64]]])\n",
      "input: torch.Size([1, 1, 4, 4, 4])\n",
      "output: torch.Size([1, 8, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor([[[1,2,3,4],\n",
    "                 [5,6,7,8],\n",
    "                 [9,10,11,12],\n",
    "                 [13,14,15,16]],\n",
    "                [[17,18,19,20],\n",
    "                 [21,22,23,24],\n",
    "                 [25,26,27,28],\n",
    "                 [29,30,31,32]],\n",
    "                [[33,34,35,36],\n",
    "                 [37,38,39,40],\n",
    "                 [41,42,43,44],\n",
    "                 [45,46,47,48]],\n",
    "                [[49,50,51,52],\n",
    "                 [53,54,55,56],\n",
    "                 [57,58,59,60],\n",
    "                 [61,62,63,64]]])\n",
    "# x=torch.rand(6,6,6)\n",
    "print('Input:',x,sep='\\n')\n",
    "x=x.reshape(1,1,4,4,4) # B,C,D,H,W\n",
    "\n",
    "model=PatchMerging(dim=x.shape[1])\n",
    "y=model(x)\n",
    "\n",
    "print('input:',x.shape)\n",
    "print('output:',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  5,  6, 17, 18, 21, 22])\n"
     ]
    }
   ],
   "source": [
    "print(y[0,:,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([33, 34, 37, 38, 49, 50, 53, 54])\n"
     ]
    }
   ],
   "source": [
    "print(y[0,:,1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3,  4,  7,  8, 19, 20, 23, 24])\n"
     ]
    }
   ],
   "source": [
    "print(y[0,:,0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35, 36, 39, 40, 51, 52, 55, 56])\n"
     ]
    }
   ],
   "source": [
    "print(y[0,:,1,0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patch Expanding 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchExpanding(nn.Module):\n",
    "    def __init__(self, dim, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.norm = norm_layer(dim//2)\n",
    "        self.expand = nn.Linear(dim, 4 * dim, bias=False)\n",
    "\n",
    "    def forward(self, y):\n",
    "        \"\"\"\n",
    "        y: B,C,D,H,W\n",
    "        \"\"\"\n",
    "        y=y.permute(0,3,4,2,1) # [B,H,W,D,C]\n",
    "        B=y.shape[0];H=y.shape[1];W=y.shape[2];D=y.shape[3];C=y.shape[4]\n",
    "\n",
    "        # channel expand\n",
    "        # y=self.expand(y) # B, H, W, D, 4*C\n",
    "\n",
    "        x=None\n",
    "        for i in range(0,D):\n",
    "            y_=y[:,:,:,i,:] # B, H, W, 1, 4*C\n",
    "            y_=y_.view(B,H,W,1,8) \n",
    "\n",
    "            # channel information -> dimension information\n",
    "            y_=y_.view(B, H, W, 2, 4) # B, H, W, 2, 2*C\n",
    "\n",
    "            # channel informatinon -> width, height information\n",
    "            rst=rearrange(y_,'b h w d (p1 p2 c)-> b (h p1) (w p2) d c', p1=2, p2=2, c=C//8) # B, 2*H, 2*W, 2, C//2\n",
    "\n",
    "            # concat\n",
    "            if i==0:\n",
    "                x=rst.clone() # B, 2*H, 2*W, 2, C//2\n",
    "            else:\n",
    "                x=torch.cat([x,rst],-2) # final shape -> [B, 2*H, 2*W, 2*D, C//2]\n",
    "                        \n",
    "        # normalization\n",
    "        # x=self.norm(x) # B, 2*H, 2*W, 2*D, C//2\n",
    "\n",
    "        x=x.permute(0,4,3,1,2) # B, C//2, 2*D, 2*H, 2*W\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.reshape(1, 8, 2, 2, 2)\n",
    "\n",
    "model=PatchExpanding(dim=y.shape[1])\n",
    "z=model(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "tensor([[[ 1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8],\n",
      "         [ 9, 10, 11, 12],\n",
      "         [13, 14, 15, 16]],\n",
      "\n",
      "        [[17, 18, 19, 20],\n",
      "         [21, 22, 23, 24],\n",
      "         [25, 26, 27, 28],\n",
      "         [29, 30, 31, 32]],\n",
      "\n",
      "        [[33, 34, 35, 36],\n",
      "         [37, 38, 39, 40],\n",
      "         [41, 42, 43, 44],\n",
      "         [45, 46, 47, 48]],\n",
      "\n",
      "        [[49, 50, 51, 52],\n",
      "         [53, 54, 55, 56],\n",
      "         [57, 58, 59, 60],\n",
      "         [61, 62, 63, 64]]])\n"
     ]
    }
   ],
   "source": [
    "z=z.view(4,4,4)\n",
    "print('Output:',z,sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
