{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNETR++ (Synapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Yaktocat](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbfoICR%2FbtrU1MMvL15%2FcwYgtGTptLML76AfvTRRM0%2Fimg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input: 128 x 128 x 64 x 1\n",
    "- Output: 128 x 128 x 64 x 14  \n",
    "<br/>\n",
    "- 구조:<br/> \n",
    "(1) input -> (encoder1) -> convblock  \n",
    "(2) input -> (UnetrPPEncoder) -> (decoder5) -> (decoder4) -> (decoder3) -> (decoder2 with convblock) -> (out1) -> output\n",
    "<br/>\n",
    "<br/>\n",
    "- 초록색 블록: UnetResBlock (Conv 3x3x3 -> Conv 3x3x3 -> skip connection) or (Conv 3x3x3 -> Conv 3x3x3 -> Conv 1x1x1 -> skip connection) <-- encoder1의 처음 ConvBlock  \n",
    "- 분홍색 블록: TFblock (reshape -> positional encoding -> EPA -> skip connection -> reshape -> UnetResBlock -> Conv 1x1x1 -> skip connection )  \n",
    "<br/>\n",
    "- 인코더: UnetrPPEncoder (embedding<2,4,4> -> TFblock x3 -> (downsample->TFblock x3) ->...)  \n",
    "<br/>\n",
    "- 파란색 블록 + 분홍색 블록 : UnetrUpBlock ((transp_conv<2,2,2> -> skip connection -> TFblock x3) ->...)) // decoder5 ~ 3  \n",
    "- 파란색 블록 + 초록색 블록 : UnetrUpBlock (transp_conv<2,4,4> -> skip connection -> UnetResBlock)  // decoder2  \n",
    "<br/>\n",
    "- 회색 블록: UnetOutBlock (Conv 1x1x1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 관련 파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1.unetr_pp/run/run_training.py -> start \\n2.unetr_pp/run/default_configuration.py -> return trainer_class \\n3-1.unetr_pp/training/network_training/unetr_pp_trainer_synapse.py -> trainer class\\n3-2.unetr_pp/training/network_training/Trainer_synapse.py -> trainer parent class\\n4.unetr_pp/network_architecture/synapse/unetr_pp_synapse.py -> network class (UNETR_PP)\\n4-1.unetr_pp/network_architecture/synapse/model_components.py -> encoder class (UnetrPPEncoder), decoder class (UnetrUpBlock)\\n4-2.unetr_pp/network_architecture/synapse/transformerblock.py -> Transformer Block, EPA class\\n4-3.unetr_pp/network_architecture/dynunet_block.py -> UnetResBlock, UnetOutBlock\\n\\n(특이사항) encoder는 한 개의 모듈(UnetrPPEncoder)로 되어 있고, decoder는 여러 개의 모듈(UnetrUpBlock)로 되어 있음\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1.unetr_pp/run/run_training.py -> start \n",
    "2.unetr_pp/run/default_configuration.py -> return trainer_class \n",
    "3-1.unetr_pp/training/network_training/unetr_pp_trainer_synapse.py -> trainer class\n",
    "3-2.unetr_pp/training/network_training/Trainer_synapse.py -> trainer parent class\n",
    "4.unetr_pp/network_architecture/synapse/unetr_pp_synapse.py -> network class (UNETR_PP)\n",
    "4-1.unetr_pp/network_architecture/synapse/model_components.py -> encoder class (UnetrPPEncoder), decoder class (UnetrUpBlock)\n",
    "4-2.unetr_pp/network_architecture/synapse/transformerblock.py -> Transformer Block, EPA class\n",
    "4-3.unetr_pp/network_architecture/dynunet_block.py -> UnetResBlock, UnetOutBlock\n",
    "\n",
    "(특이사항) encoder는 한 개의 모듈(UnetrPPEncoder)로 되어 있고, decoder는 여러 개의 모듈(UnetrUpBlock)로 되어 있음\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fold validation 설정 확인  \n",
    "(fold 0만 이용한다고 함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 OrderedDict([('train', array(['img0001', 'img0002', 'img0003', 'img0005', 'img0006', 'img0007',\n",
      "       'img0008', 'img0010', 'img0021', 'img0022', 'img0024', 'img0025',\n",
      "       'img0027', 'img0028', 'img0030', 'img0031', 'img0032', 'img0033',\n",
      "       'img0034', 'img0035', 'img0036', 'img0038', 'img0039', 'img0040'],\n",
      "      dtype='<U7')), ('val', array(['img0004', 'img0009', 'img0023', 'img0026', 'img0029', 'img0037'],\n",
      "      dtype='<U7'))])\n",
      "\n",
      "1 OrderedDict([('train', array(['img0002', 'img0003', 'img0004', 'img0005', 'img0006', 'img0009',\n",
      "       'img0010', 'img0021', 'img0022', 'img0023', 'img0024', 'img0025',\n",
      "       'img0026', 'img0027', 'img0028', 'img0029', 'img0030', 'img0033',\n",
      "       'img0034', 'img0036', 'img0037', 'img0038', 'img0039', 'img0040'],\n",
      "      dtype='<U7')), ('val', array(['img0001', 'img0007', 'img0008', 'img0031', 'img0032', 'img0035'],\n",
      "      dtype='<U7'))])\n",
      "\n",
      "2 OrderedDict([('train', array(['img0001', 'img0002', 'img0003', 'img0004', 'img0005', 'img0006',\n",
      "       'img0007', 'img0008', 'img0009', 'img0010', 'img0023', 'img0025',\n",
      "       'img0026', 'img0027', 'img0028', 'img0029', 'img0031', 'img0032',\n",
      "       'img0035', 'img0036', 'img0037', 'img0038', 'img0039', 'img0040'],\n",
      "      dtype='<U7')), ('val', array(['img0021', 'img0022', 'img0024', 'img0030', 'img0033', 'img0034'],\n",
      "      dtype='<U7'))])\n",
      "\n",
      "3 OrderedDict([('train', array(['img0001', 'img0002', 'img0003', 'img0004', 'img0005', 'img0006',\n",
      "       'img0007', 'img0008', 'img0009', 'img0010', 'img0021', 'img0022',\n",
      "       'img0023', 'img0024', 'img0026', 'img0029', 'img0030', 'img0031',\n",
      "       'img0032', 'img0033', 'img0034', 'img0035', 'img0037', 'img0039'],\n",
      "      dtype='<U7')), ('val', array(['img0025', 'img0027', 'img0028', 'img0036', 'img0038', 'img0040'],\n",
      "      dtype='<U7'))])\n",
      "\n",
      "4 OrderedDict([('train', array(['img0001', 'img0004', 'img0007', 'img0008', 'img0009', 'img0021',\n",
      "       'img0022', 'img0023', 'img0024', 'img0025', 'img0026', 'img0027',\n",
      "       'img0028', 'img0029', 'img0030', 'img0031', 'img0032', 'img0033',\n",
      "       'img0034', 'img0035', 'img0036', 'img0037', 'img0038', 'img0040'],\n",
      "      dtype='<U7')), ('val', array(['img0002', 'img0003', 'img0005', 'img0006', 'img0010', 'img0039'],\n",
      "      dtype='<U7'))])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path='/media/ahnsunghyun/HDD/pytorch_hdd/unetr_plus_plus/DATASET/unetr_pp_raw/unetr_pp_raw_data/Task02_Synapse/Task002_Synapse/splits_final.pkl'\n",
    "data = pd.read_pickle(path)\n",
    "for i,dt in enumerate(data):\n",
    "    print(i,dt)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 18 training and 12 validation cases:    \n",
    "  \n",
    "['img0005', 'img0006', 'img0007', 'img0009', 'img0010', 'img0021', 'img0023', 'img0024', 'img0026', 'img0027', 'img0028', 'img0030', 'img0031', 'img0033', 'img0034', 'img0037', 'img0039', 'img0040'],  \n",
    "['img0001', 'img0002', 'img0003', 'img0004', 'img0008', 'img0022', 'img0025', 'img0029', 'img0032', 'img0035', 'img0036', 'img0038']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synapse 데이터셋 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_modalities: 1\n",
      "\n",
      "len(data): 30\n",
      "\n",
      "original_sizes: [(147, 512, 512), (139, 512, 512), (198, 512, 512), (140, 512, 512), (117, 512, 512), (131, 512, 512), (163, 512, 512), (148, 512, 512), (149, 512, 512), (148, 512, 512), (143, 512, 512), (89, 512, 512), (96, 512, 512), (124, 512, 512), (85, 512, 512), (131, 512, 512), (88, 512, 512), (89, 512, 512), (100, 512, 512), (153, 512, 512), (93, 512, 512), (144, 512, 512), (104, 512, 512), (98, 512, 512), (94, 512, 512), (184, 512, 512), (99, 512, 512), (100, 512, 512), (90, 512, 512), (195, 512, 512)]\n",
      "\n",
      "preprocessed_data_folder: ../DATASET/nnFormer_raw/nnFormer_raw_data/Task02_Synapse/Task002_Synapse\n",
      "\n",
      "all_classes: [1, 10, 11, 12, 13, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "\n",
      "base_num_features: 32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path2='/media/ahnsunghyun/HDD/pytorch_hdd/unetr_plus_plus/DATASET/unetr_pp_raw/unetr_pp_raw_data/Task02_Synapse/Task002_Synapse/unetr_pp_Plansv2.1_plans_3D.pkl'\n",
    "plans = pd.read_pickle(path2)\n",
    "print('num_modalities:',plans['num_modalities'], end='\\n\\n')\n",
    "print('len(data):',len(plans['dataset_properties']['all_sizes']), end='\\n\\n')\n",
    "print('original_sizes:',plans['original_sizes'], end='\\n\\n')\n",
    "print('preprocessed_data_folder:',plans['preprocessed_data_folder'], end='\\n\\n')\n",
    "print('all_classes:',plans['all_classes'], end='\\n\\n')\n",
    "print('base_num_features:',plans['base_num_features'], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "base_num_features: patch_embedding 이후 첫 번째 채널 수 (32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "배치 사이즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "stage = list(plans['plans_per_stage'].keys())[0]\n",
    "stage_plans = plans['plans_per_stage'][stage]\n",
    "batch_size = stage_plans['batch_size']\n",
    "print(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 구조  \n",
    "(unetr_pp/training/network_training/unetr_pp_trainer_synapse.py,  Trainer_synapse.py 참조)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:115.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_model_summary import summary\n",
    "from unetr_pp.network_architecture.synapse.unetr_pp_synapse import UNETR_PP\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = plans['num_modalities']\n",
    "num_classes=plans['num_classes'] + 1  # organ category + background\n",
    "crop_size = [64, 128, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================HyperParameters=============================\n",
      "input_channels : 1\n",
      "num_classes : 14\n",
      "crop_size : [64, 128, 128]\n",
      "feature_size : 16\n",
      "num_heads : 4\n",
      "depths : [3, 3, 3, 3]\n",
      "dims : [32, 64, 128, 256]\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "print('===========================HyperParameters=============================')\n",
    "print('input_channels',':',input_channels)\n",
    "print('num_classes',':',num_classes)\n",
    "print('crop_size',':',crop_size)\n",
    "print('feature_size',':',16)\n",
    "print('num_heads',':',4)\n",
    "print('depths',':',[3, 3, 3, 3])\n",
    "print('dims',':',[32, 64, 128, 256])\n",
    "print('=========================================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인코더1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([1, 16, 64, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "from unetr_pp.network_architecture.dynunet_block import UnetResBlock\n",
    "\n",
    "# 네트워크\n",
    "encoder1 = UnetResBlock(\n",
    "            spatial_dims=3,\n",
    "            in_channels=1,\n",
    "            out_channels=16,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            norm_name=\"instance\",\n",
    "        )\n",
    "\n",
    "# 테스트\n",
    "input=torch.zeros(1, 1, 64, 128, 128) # Input Shape : [B, C, D, H, W]\n",
    "output=encoder1(input) \n",
    "print('output shape:',output.shape) # Output Shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인코더 (수축경로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([1, 64, 256])\n",
      "hidden_states:\n",
      "0 : torch.Size([1, 32, 32, 32, 32])\n",
      "1 : torch.Size([1, 64, 16, 16, 16])\n",
      "2 : torch.Size([1, 128, 8, 8, 8])\n",
      "3 : torch.Size([1, 64, 256])\n"
     ]
    }
   ],
   "source": [
    "from unetr_plus_plus.unetr_pp.network_architecture.synapse.model_components import UnetrPPEncoder\n",
    "\n",
    "# 네트워크\n",
    "unetr_pp_encoder = UnetrPPEncoder(dims=[32,64,128,256], depths=[3,3,3,3], num_heads=4)\n",
    "\n",
    "# 테스트\n",
    "input=torch.zeros(1, 1, 64, 128, 128) # Input Shape : [B, C, D, H, W]\n",
    "output, hidden_states=unetr_pp_encoder(input) \n",
    "print('output shape:',output.shape) # Output Shape\n",
    "print('hidden_states:')\n",
    "for i,hd in enumerate(hidden_states):\n",
    "    print(i,':',hd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "proj_feat (인코더 출력 shape 변경)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: torch.Size([1, 64, 256])\n",
      "output: torch.Size([1, 256, 4, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# 네트워크\n",
    "def proj_feat(x, hidden_size, feat_size):\n",
    "    x = x.view(x.size(0), feat_size[0], feat_size[1], feat_size[2], hidden_size)\n",
    "    x = x.permute(0, 4, 1, 2, 3).contiguous()\n",
    "    return x\n",
    "\n",
    "# 테스트\n",
    "enc4 = hidden_states[3]\n",
    "dec4 =proj_feat(enc4, 256,[4,4,4])\n",
    "print('input:',enc4.shape)\n",
    "print('output:',dec4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UnetrUpBlock (decoder5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input(dec4,enc3): torch.Size([1, 256, 4, 4, 4]) torch.Size([1, 128, 8, 8, 8])\n",
      "output: torch.Size([1, 128, 8, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "from unetr_pp.network_architecture.synapse.model_components import UnetrUpBlock\n",
    "\n",
    "feature_size=16\n",
    "\n",
    "# 네트워크\n",
    "decoder5 = UnetrUpBlock(\n",
    "            spatial_dims=3,\n",
    "            in_channels=feature_size * 16,\n",
    "            out_channels=feature_size * 8,\n",
    "            kernel_size=3,\n",
    "            upsample_kernel_size=2,\n",
    "            norm_name=\"instance\",\n",
    "            out_size=8 * 8 * 8,\n",
    "        )\n",
    "\n",
    "# 테스트\n",
    "dec4=torch.zeros(1,256,4,4,4)\n",
    "enc3=hidden_states[2] # [1, 128, 8, 8, 8]\n",
    "dec3=decoder5(dec4,enc3)\n",
    "print('input(dec4,enc3):',dec4.shape, enc3.shape)\n",
    "print('output:',dec3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UnetrUpBlock (decoder2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input(dec1,convBlock): torch.Size([1, 32, 32, 32, 32]) torch.Size([1, 16, 64, 128, 128])\n",
      "output: torch.Size([1, 16, 64, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# 네트워크\n",
    "decoder2 = UnetrUpBlock(\n",
    "            spatial_dims=3,\n",
    "            in_channels=feature_size * 2,\n",
    "            out_channels=feature_size,\n",
    "            kernel_size=3,\n",
    "            upsample_kernel_size=(2, 4, 4),\n",
    "            norm_name=\"instance\",\n",
    "            out_size=64 * 128 * 128,\n",
    "            conv_decoder=True,\n",
    "        )\n",
    "\n",
    "# 테스트\n",
    "dec1=torch.zeros(1,32,32,32,32) \n",
    "convBlock=torch.zeros(1,16,64,128,128)\n",
    "out=decoder2(dec1,convBlock)\n",
    "print('input(dec1,convBlock):',dec1.shape, convBlock.shape)\n",
    "print('output:',out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: torch.Size([1, 16, 64, 128, 128])\n",
      "output: torch.Size([1, 14, 64, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "from unetr_pp.network_architecture.dynunet_block import UnetOutBlock, UnetResBlock\n",
    "\n",
    "out_channels=14\n",
    "\n",
    "# 네트워크\n",
    "out1 = UnetOutBlock(spatial_dims=3, in_channels=feature_size, out_channels=out_channels)\n",
    "\n",
    "# 테스트\n",
    "input=torch.zeros(1,16,64,128,128)\n",
    "logits = out1(input)\n",
    "print('input:',input.shape)\n",
    "print('output:',logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "       Layer (type)                                    Input Shape         Param #     Tr. Param #\n",
      "===================================================================================================\n",
      "   UnetrPPEncoder-1                           [1, 1, 64, 128, 128]      27,387,232      27,387,232\n",
      "     UnetResBlock-2                           [1, 1, 64, 128, 128]           7,360           7,360\n",
      "     UnetrUpBlock-3           [1, 256, 4, 4, 4], [1, 128, 8, 8, 8]       3,509,848       3,509,848\n",
      "     UnetrUpBlock-4         [1, 128, 8, 8, 8], [1, 64, 16, 16, 16]       2,377,624       2,377,624\n",
      "     UnetrUpBlock-5       [1, 64, 16, 16, 16], [1, 32, 32, 32, 32]       9,638,968       9,638,968\n",
      "     UnetrUpBlock-6     [1, 32, 32, 32, 32], [1, 16, 64, 128, 128]          30,208          30,208\n",
      "     UnetOutBlock-7                          [1, 16, 64, 128, 128]             238             238\n",
      "     UnetOutBlock-8                            [1, 32, 32, 32, 32]             462             462\n",
      "     UnetOutBlock-9                            [1, 64, 16, 16, 16]             910             910\n",
      "===================================================================================================\n",
      "Total params: 42,952,850\n",
      "Trainable params: 42,952,850\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------------------------------\n",
      "output shape:\n",
      "0 : torch.Size([1, 14, 64, 128, 128])\n",
      "1 : torch.Size([1, 14, 32, 32, 32])\n",
      "2 : torch.Size([1, 14, 16, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "# 네트워크\n",
    "network = UNETR_PP(in_channels=input_channels,\n",
    "                   out_channels=num_classes,\n",
    "                   img_size=crop_size,\n",
    "                   feature_size=16,\n",
    "                   num_heads=4,\n",
    "                   depths=[3, 3, 3, 3],\n",
    "                   dims=[32, 64, 128, 256],\n",
    "                   do_ds=True,)\n",
    "network=network.to(device) # Network\n",
    "\n",
    "# 모델 요약 및 테스트\n",
    "input=torch.zeros(1, 1, 64, 128, 128) # Input Shape : [B, C, D, H, W]\n",
    "print(summary(network, input, show_input=True)) # Forwarding Shape\n",
    "output=network(input) \n",
    "print('output shape:') # Output Shape\n",
    "for i,out in enumerate(output):\n",
    "    print(i,':',out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: [1, 1, 64, 128, 128] ->  \n",
    "(UnetrPPEncoder-1) ->  [1, 256, 4, 4, 4] ->  \n",
    "(UnetrUpBlock-3, decoder5) -> [1, 128, 8, 8, 8] ->  \n",
    "(UnetrUpBlock-4, decoder4) ->  [1, 64, 16, 16, 16] ->  \n",
    "(UnetrUpBlock-5, decoder3) ->  [1, 32, 32, 32, 32] ->  \n",
    "(UnetrUpBlock-6, decoder2) ->  [1, 16, 64, 128, 128] ->  \n",
    "(UnetOutBlock-7, out1) -> [1, 14, 64, 128, 128]  \n",
    "Output: [1, 14, 64, 128, 128]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output이 3개인 이유는 unet++의 deep supervision을 이용하기 때문이다.  \n",
    "즉 multiple output을 평균짓고 Loss를 구하겠다는 것인데, 이렇게 하면 multiple semantic level의 feature map을 획득할 수 있다고 한다.  \n",
    "-> 더 좋은 성능을 보임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 전체 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of UNETR_PP(\n",
       "  (unetr_pp_encoder): UnetrPPEncoder(\n",
       "    (downsample_layers): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Convolution(\n",
       "          (conv): Conv3d(1, 32, kernel_size=(2, 4, 4), stride=(2, 4, 4), bias=False)\n",
       "        )\n",
       "        (1): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Convolution(\n",
       "          (conv): Conv3d(32, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "        )\n",
       "        (1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Convolution(\n",
       "          (conv): Conv3d(64, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "        )\n",
       "        (1): GroupNorm(64, 128, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Convolution(\n",
       "          (conv): Conv3d(128, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "        )\n",
       "        (1): GroupNorm(128, 256, eps=1e-05, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (stages): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): TransformerBlock(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): EPA(\n",
       "            (qkvv): Linear(in_features=32, out_features=128, bias=False)\n",
       "            (E): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (F): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "            (out_proj): Linear(in_features=32, out_features=16, bias=True)\n",
       "            (out_proj2): Linear(in_features=32, out_features=16, bias=True)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): EPA(\n",
       "            (qkvv): Linear(in_features=32, out_features=128, bias=False)\n",
       "            (E): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (F): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "            (out_proj): Linear(in_features=32, out_features=16, bias=True)\n",
       "            (out_proj2): Linear(in_features=32, out_features=16, bias=True)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): EPA(\n",
       "            (qkvv): Linear(in_features=32, out_features=128, bias=False)\n",
       "            (E): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (F): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "            (out_proj): Linear(in_features=32, out_features=16, bias=True)\n",
       "            (out_proj2): Linear(in_features=32, out_features=16, bias=True)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): TransformerBlock(\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): EPA(\n",
       "            (qkvv): Linear(in_features=64, out_features=256, bias=False)\n",
       "            (E): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (F): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "            (out_proj): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (out_proj2): Linear(in_features=64, out_features=32, bias=True)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): EPA(\n",
       "            (qkvv): Linear(in_features=64, out_features=256, bias=False)\n",
       "            (E): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (F): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "            (out_proj): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (out_proj2): Linear(in_features=64, out_features=32, bias=True)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): EPA(\n",
       "            (qkvv): Linear(in_features=64, out_features=256, bias=False)\n",
       "            (E): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (F): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "            (out_proj): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (out_proj2): Linear(in_features=64, out_features=32, bias=True)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): TransformerBlock(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): EPA(\n",
       "            (qkvv): Linear(in_features=128, out_features=512, bias=False)\n",
       "            (E): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (F): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "            (out_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "            (out_proj2): Linear(in_features=128, out_features=64, bias=True)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): EPA(\n",
       "            (qkvv): Linear(in_features=128, out_features=512, bias=False)\n",
       "            (E): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (F): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "            (out_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "            (out_proj2): Linear(in_features=128, out_features=64, bias=True)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): EPA(\n",
       "            (qkvv): Linear(in_features=128, out_features=512, bias=False)\n",
       "            (E): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (F): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "            (out_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "            (out_proj2): Linear(in_features=128, out_features=64, bias=True)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): TransformerBlock(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): EPA(\n",
       "            (qkvv): Linear(in_features=256, out_features=1024, bias=False)\n",
       "            (E): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (F): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (out_proj2): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): EPA(\n",
       "            (qkvv): Linear(in_features=256, out_features=1024, bias=False)\n",
       "            (E): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (F): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (out_proj2): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): EPA(\n",
       "            (qkvv): Linear(in_features=256, out_features=1024, bias=False)\n",
       "            (E): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (F): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (out_proj2): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder1): UnetResBlock(\n",
       "    (conv1): Convolution(\n",
       "      (conv): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (conv2): Convolution(\n",
       "      (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (norm1): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (norm2): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (conv3): Convolution(\n",
       "      (conv): Conv3d(1, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (norm3): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  )\n",
       "  (decoder5): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (decoder_block): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): TransformerBlock(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): EPA(\n",
       "            (qkvv): Linear(in_features=128, out_features=512, bias=False)\n",
       "            (E): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (F): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "            (out_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "            (out_proj2): Linear(in_features=128, out_features=64, bias=True)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): EPA(\n",
       "            (qkvv): Linear(in_features=128, out_features=512, bias=False)\n",
       "            (E): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (F): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "            (out_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "            (out_proj2): Linear(in_features=128, out_features=64, bias=True)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): EPA(\n",
       "            (qkvv): Linear(in_features=128, out_features=512, bias=False)\n",
       "            (E): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (F): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "            (out_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "            (out_proj2): Linear(in_features=128, out_features=64, bias=True)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder4): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (decoder_block): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): TransformerBlock(\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): EPA(\n",
       "            (qkvv): Linear(in_features=64, out_features=256, bias=False)\n",
       "            (E): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (F): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "            (out_proj): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (out_proj2): Linear(in_features=64, out_features=32, bias=True)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): EPA(\n",
       "            (qkvv): Linear(in_features=64, out_features=256, bias=False)\n",
       "            (E): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (F): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "            (out_proj): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (out_proj2): Linear(in_features=64, out_features=32, bias=True)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): EPA(\n",
       "            (qkvv): Linear(in_features=64, out_features=256, bias=False)\n",
       "            (E): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (F): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "            (out_proj): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (out_proj2): Linear(in_features=64, out_features=32, bias=True)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder3): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (decoder_block): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): TransformerBlock(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): EPA(\n",
       "            (qkvv): Linear(in_features=32, out_features=128, bias=False)\n",
       "            (E): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (F): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "            (out_proj): Linear(in_features=32, out_features=16, bias=True)\n",
       "            (out_proj2): Linear(in_features=32, out_features=16, bias=True)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): EPA(\n",
       "            (qkvv): Linear(in_features=32, out_features=128, bias=False)\n",
       "            (E): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (F): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "            (out_proj): Linear(in_features=32, out_features=16, bias=True)\n",
       "            (out_proj2): Linear(in_features=32, out_features=16, bias=True)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): EPA(\n",
       "            (qkvv): Linear(in_features=32, out_features=128, bias=False)\n",
       "            (E): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (F): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "            (out_proj): Linear(in_features=32, out_features=16, bias=True)\n",
       "            (out_proj2): Linear(in_features=32, out_features=16, bias=True)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder2): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(32, 16, kernel_size=(2, 4, 4), stride=(2, 4, 4), bias=False)\n",
       "    )\n",
       "    (decoder_block): ModuleList(\n",
       "      (0): UnetResBlock(\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (norm1): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (norm2): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out1): UnetOutBlock(\n",
       "    (conv): Convolution(\n",
       "      (conv): Conv3d(16, 14, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (out2): UnetOutBlock(\n",
       "    (conv): Convolution(\n",
       "      (conv): Conv3d(32, 14, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (out3): UnetOutBlock(\n",
       "    (conv): Convolution(\n",
       "      (conv): Conv3d(64, 14, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.parameters"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
