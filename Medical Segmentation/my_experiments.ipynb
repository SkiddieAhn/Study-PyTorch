{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My_UNETR++ (Synapese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 구조  \n",
    "(my_unetr_pp/training/network_training/unetr_pp_trainer_synapse.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('my_unetr_plus_plus')\n",
    " \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_model_summary import summary\n",
    "from my_unetr_plus_plus.unetr_pp.network_architecture.synapse.unetr_pp_synapse import UNETR_PP\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels=1\n",
    "num_classes=14\n",
    "crop_size=[64, 128, 128]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 모델  \n",
    "(encoder와 decoder에 nfce 모듈 적용됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "       Layer (type)                                    Input Shape         Param #     Tr. Param #\n",
      "===================================================================================================\n",
      "   UnetrPPEncoder-1                           [1, 1, 64, 128, 128]      26,919,880      26,919,880\n",
      "     UnetResBlock-2                           [1, 1, 64, 128, 128]           7,360           7,360\n",
      "           My_TIF-3           [1, 128, 8, 8, 8], [1, 256, 4, 4, 4]       2,368,256       2,368,256\n",
      "           My_TIF-4         [1, 64, 16, 16, 16], [1, 128, 8, 8, 8]         920,256         920,256\n",
      "           My_TIF-5       [1, 32, 32, 32, 32], [1, 64, 16, 16, 16]       2,537,120       2,537,120\n",
      "     UnetrUpBlock-6           [1, 256, 4, 4, 4], [1, 128, 8, 8, 8]       3,421,880       3,421,880\n",
      "     UnetrUpBlock-7         [1, 128, 8, 8, 8], [1, 64, 16, 16, 16]       2,355,912       2,355,912\n",
      "     UnetrUpBlock-8       [1, 64, 16, 16, 16], [1, 32, 32, 32, 32]       9,633,680       9,633,680\n",
      "     UnetrUpBlock-9     [1, 32, 32, 32, 32], [1, 16, 64, 128, 128]          30,508          30,508\n",
      "    UnetOutBlock-10                          [1, 16, 64, 128, 128]             238             238\n",
      "    UnetOutBlock-11                            [1, 32, 32, 32, 32]             462             462\n",
      "    UnetOutBlock-12                            [1, 64, 16, 16, 16]             910             910\n",
      "===================================================================================================\n",
      "Total params: 48,196,462\n",
      "Trainable params: 48,196,462\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------------------------------\n",
      "output shape:\n",
      "0 : torch.Size([1, 14, 64, 128, 128])\n",
      "1 : torch.Size([1, 14, 32, 32, 32])\n",
      "2 : torch.Size([1, 14, 16, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "# 네트워크\n",
    "network = UNETR_PP(in_channels=input_channels,\n",
    "                   out_channels=num_classes,\n",
    "                   img_size=crop_size,\n",
    "                   feature_size=16,\n",
    "                   num_heads=4,\n",
    "                   depths=[3, 3, 3, 3],\n",
    "                   dims=[32, 64, 128, 256],\n",
    "                   do_ds=True,)\n",
    "network=network.to(device) # Network\n",
    "\n",
    "# 모델 요약 및 테스트\n",
    "input=torch.zeros(1, 1, 64, 128, 128).cuda() # Input Shape : [B, C, D, H, W]\n",
    "print(summary(network, input, show_input=True)) # Forwarding Shape\n",
    "output=network(input) \n",
    "print('output shape:') # Output Shape\n",
    "for i,out in enumerate(output):\n",
    "    print(i,':',out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of UNETR_PP(\n",
       "  (unetr_pp_encoder): UnetrPPEncoder(\n",
       "    (downsample_layers): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Convolution(\n",
       "          (conv): Conv3d(1, 32, kernel_size=(2, 4, 4), stride=(2, 4, 4), bias=False)\n",
       "        )\n",
       "        (1): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): My_PatchMerging(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (reduction): Linear(in_features=256, out_features=64, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): My_PatchMerging(\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (reduction): Linear(in_features=512, out_features=128, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): My_PatchMerging(\n",
       "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (reduction): Linear(in_features=1024, out_features=256, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (my_nfce_layers): ModuleList(\n",
       "      (0): My_NFCE(\n",
       "        (conv1): Conv3d(32, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (norm1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dsconv): Sequential(\n",
       "          (0): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=8, bias=False)\n",
       "          (1): Conv3d(8, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (norm2): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (norm3): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): My_NFCE(\n",
       "        (conv1): Conv3d(64, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (norm1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dsconv): Sequential(\n",
       "          (0): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=16, bias=False)\n",
       "          (1): Conv3d(16, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (norm2): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(16, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (norm3): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): My_NFCE(\n",
       "        (conv1): Conv3d(128, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dsconv): Sequential(\n",
       "          (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "          (1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (norm2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (norm3): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (3): My_NFCE(\n",
       "        (conv1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dsconv): Sequential(\n",
       "          (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=64, bias=False)\n",
       "          (1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (norm3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (stages): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): TransformerBlock(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): My_EPA(\n",
       "            (qkv): Linear(in_features=32, out_features=96, bias=False)\n",
       "            (proj_q): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (proj_k): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (proj_v): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): My_EPA(\n",
       "            (qkv): Linear(in_features=32, out_features=96, bias=False)\n",
       "            (proj_q): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (proj_k): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (proj_v): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): My_EPA(\n",
       "            (qkv): Linear(in_features=32, out_features=96, bias=False)\n",
       "            (proj_q): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (proj_k): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (proj_v): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): TransformerBlock(\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): My_EPA(\n",
       "            (qkv): Linear(in_features=64, out_features=192, bias=False)\n",
       "            (proj_q): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (proj_k): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (proj_v): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): My_EPA(\n",
       "            (qkv): Linear(in_features=64, out_features=192, bias=False)\n",
       "            (proj_q): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (proj_k): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (proj_v): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): My_EPA(\n",
       "            (qkv): Linear(in_features=64, out_features=192, bias=False)\n",
       "            (proj_q): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (proj_k): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (proj_v): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): TransformerBlock(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): My_EPA(\n",
       "            (qkv): Linear(in_features=128, out_features=384, bias=False)\n",
       "            (proj_q): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (proj_k): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (proj_v): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): My_EPA(\n",
       "            (qkv): Linear(in_features=128, out_features=384, bias=False)\n",
       "            (proj_q): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (proj_k): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (proj_v): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): My_EPA(\n",
       "            (qkv): Linear(in_features=128, out_features=384, bias=False)\n",
       "            (proj_q): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (proj_k): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (proj_v): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): TransformerBlock(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): My_EPA(\n",
       "            (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (proj_q): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (proj_k): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (proj_v): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): My_EPA(\n",
       "            (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (proj_q): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (proj_k): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (proj_v): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): My_EPA(\n",
       "            (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
       "            (proj_q): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (proj_k): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (proj_v): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder1): UnetResBlock(\n",
       "    (conv1): Convolution(\n",
       "      (conv): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (conv2): Convolution(\n",
       "      (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (norm1): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (norm2): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (conv3): Convolution(\n",
       "      (conv): Conv3d(1, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (norm3): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  )\n",
       "  (decoder4): UnetrUpBlock(\n",
       "    (upsampling): My_PatchExpanding(\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (expand): Linear(in_features=256, out_features=1024, bias=False)\n",
       "    )\n",
       "    (my_nfce): My_NFCE(\n",
       "      (conv1): Conv3d(128, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dsconv): Sequential(\n",
       "        (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=32, bias=False)\n",
       "        (1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (norm3): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (decoder_block): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): TransformerBlock(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): My_EPA(\n",
       "            (qkv): Linear(in_features=128, out_features=384, bias=False)\n",
       "            (proj_q): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (proj_k): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (proj_v): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): My_EPA(\n",
       "            (qkv): Linear(in_features=128, out_features=384, bias=False)\n",
       "            (proj_q): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (proj_k): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (proj_v): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): My_EPA(\n",
       "            (qkv): Linear(in_features=128, out_features=384, bias=False)\n",
       "            (proj_q): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (proj_k): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (proj_v): Linear(in_features=512, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder3): UnetrUpBlock(\n",
       "    (upsampling): My_PatchExpanding(\n",
       "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (expand): Linear(in_features=128, out_features=512, bias=False)\n",
       "    )\n",
       "    (my_nfce): My_NFCE(\n",
       "      (conv1): Conv3d(64, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (norm1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dsconv): Sequential(\n",
       "        (0): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=16, bias=False)\n",
       "        (1): Conv3d(16, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(16, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (norm3): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (decoder_block): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): TransformerBlock(\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): My_EPA(\n",
       "            (qkv): Linear(in_features=64, out_features=192, bias=False)\n",
       "            (proj_q): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (proj_k): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (proj_v): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): My_EPA(\n",
       "            (qkv): Linear(in_features=64, out_features=192, bias=False)\n",
       "            (proj_q): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (proj_k): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (proj_v): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): My_EPA(\n",
       "            (qkv): Linear(in_features=64, out_features=192, bias=False)\n",
       "            (proj_q): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (proj_k): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (proj_v): Linear(in_features=4096, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder2): UnetrUpBlock(\n",
       "    (upsampling): My_PatchExpanding(\n",
       "      (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (expand): Linear(in_features=64, out_features=256, bias=False)\n",
       "    )\n",
       "    (my_nfce): My_NFCE(\n",
       "      (conv1): Conv3d(32, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (norm1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dsconv): Sequential(\n",
       "        (0): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=8, bias=False)\n",
       "        (1): Conv3d(8, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (norm3): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (decoder_block): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): TransformerBlock(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): My_EPA(\n",
       "            (qkv): Linear(in_features=32, out_features=96, bias=False)\n",
       "            (proj_q): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (proj_k): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (proj_v): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): My_EPA(\n",
       "            (qkv): Linear(in_features=32, out_features=96, bias=False)\n",
       "            (proj_q): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (proj_k): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (proj_v): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (epa_block): My_EPA(\n",
       "            (qkv): Linear(in_features=32, out_features=96, bias=False)\n",
       "            (proj_q): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (proj_k): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (proj_v): Linear(in_features=32768, out_features=64, bias=True)\n",
       "            (attn_drop): Dropout(p=0.15, inplace=False)\n",
       "            (attn_drop_2): Dropout(p=0.15, inplace=False)\n",
       "          )\n",
       "          (conv51): UnetResBlock(\n",
       "            (conv1): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Convolution(\n",
       "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "            )\n",
       "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (norm2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv8): Sequential(\n",
       "            (0): Dropout3d(p=0.1, inplace=False)\n",
       "            (1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder1): UnetrUpBlock(\n",
       "    (upsampling): Convolution(\n",
       "      (conv): ConvTranspose3d(32, 16, kernel_size=(2, 4, 4), stride=(2, 4, 4), bias=False)\n",
       "    )\n",
       "    (my_nfce): My_NFCE(\n",
       "      (conv1): Conv3d(16, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (norm1): BatchNorm3d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dsconv): Sequential(\n",
       "        (0): Conv3d(4, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=4, bias=False)\n",
       "        (1): Conv3d(4, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm2): BatchNorm3d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(4, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (norm3): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (decoder_block): ModuleList(\n",
       "      (0): UnetResBlock(\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (norm1): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (norm2): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fusion3): My_TIF(\n",
       "    (cross_attn): My_Cross_Att(\n",
       "      (transformer_e): My_Transformer(\n",
       "        (layers): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): PreNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): My_Attention(\n",
       "                (to_qkv): Linear(in_features=128, out_features=384, bias=False)\n",
       "                (E): Linear(in_features=513, out_features=64, bias=True)\n",
       "                (F): Linear(in_features=513, out_features=64, bias=True)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): PreNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                  (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (4): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (transformer_r): My_Transformer(\n",
       "        (layers): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): PreNorm(\n",
       "              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): My_Attention(\n",
       "                (to_qkv): Linear(in_features=256, out_features=768, bias=False)\n",
       "                (E): Linear(in_features=65, out_features=64, bias=True)\n",
       "                (F): Linear(in_features=65, out_features=64, bias=True)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): PreNorm(\n",
       "              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                  (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (4): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_e): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm_r): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "      (linear_e): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (linear_r): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "    (up): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (conv): My_Conv_block(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv3d(384, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (4): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fusion2): My_TIF(\n",
       "    (cross_attn): My_Cross_Att(\n",
       "      (transformer_e): My_Transformer(\n",
       "        (layers): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): PreNorm(\n",
       "              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): My_Attention(\n",
       "                (to_qkv): Linear(in_features=64, out_features=192, bias=False)\n",
       "                (E): Linear(in_features=4097, out_features=64, bias=True)\n",
       "                (F): Linear(in_features=4097, out_features=64, bias=True)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): PreNorm(\n",
       "              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                  (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "                  (4): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (transformer_r): My_Transformer(\n",
       "        (layers): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): PreNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): My_Attention(\n",
       "                (to_qkv): Linear(in_features=128, out_features=384, bias=False)\n",
       "                (E): Linear(in_features=513, out_features=64, bias=True)\n",
       "                (F): Linear(in_features=513, out_features=64, bias=True)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): PreNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                  (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "                  (4): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_e): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm_r): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "      (linear_e): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (linear_r): Linear(in_features=128, out_features=64, bias=True)\n",
       "    )\n",
       "    (up): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (conv): My_Conv_block(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv3d(192, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (4): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fusion1): My_TIF(\n",
       "    (cross_attn): My_Cross_Att(\n",
       "      (transformer_e): My_Transformer(\n",
       "        (layers): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): PreNorm(\n",
       "              (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): My_Attention(\n",
       "                (to_qkv): Linear(in_features=32, out_features=96, bias=False)\n",
       "                (E): Linear(in_features=32769, out_features=64, bias=True)\n",
       "                (F): Linear(in_features=32769, out_features=64, bias=True)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): PreNorm(\n",
       "              (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                  (3): Linear(in_features=128, out_features=32, bias=True)\n",
       "                  (4): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (transformer_r): My_Transformer(\n",
       "        (layers): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): PreNorm(\n",
       "              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): My_Attention(\n",
       "                (to_qkv): Linear(in_features=64, out_features=192, bias=False)\n",
       "                (E): Linear(in_features=4097, out_features=64, bias=True)\n",
       "                (F): Linear(in_features=4097, out_features=64, bias=True)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): PreNorm(\n",
       "              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                  (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "                  (4): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_e): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm_r): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "      (linear_e): Linear(in_features=32, out_features=64, bias=True)\n",
       "      (linear_r): Linear(in_features=64, out_features=32, bias=True)\n",
       "    )\n",
       "    (up): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (conv): My_Conv_block(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv3d(96, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (4): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out1): UnetOutBlock(\n",
       "    (conv): Convolution(\n",
       "      (conv): Conv3d(16, 14, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (out2): UnetOutBlock(\n",
       "    (conv): Convolution(\n",
       "      (conv): Conv3d(32, 14, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (out3): UnetOutBlock(\n",
       "    (conv): Convolution(\n",
       "      (conv): Conv3d(64, 14, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.parameters"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
