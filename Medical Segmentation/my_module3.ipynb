{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytorch_model_summary import summary\n",
    "from einops import rearrange\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    r\"\"\" LayerNorm that supports two data formats: channels_last (default) or channels_first. \n",
    "    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with \n",
    "    shape (batch_size, height, width, channels) while channels_first corresponds to inputs \n",
    "    with shape (batch_size, channels, height, width).\n",
    "    \"\"\"\n",
    "    def __init__(self, normalized_shape, eps=1e-6, data_format=\"channels_last\"):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
    "        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
    "        self.eps = eps\n",
    "        self.data_format = data_format\n",
    "        if self.data_format not in [\"channels_last\", \"channels_first\"]:\n",
    "            raise NotImplementedError \n",
    "        self.normalized_shape = (normalized_shape, )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.data_format == \"channels_last\":\n",
    "            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
    "        elif self.data_format == \"channels_first\":\n",
    "            u = x.mean(1, keepdim=True)\n",
    "            s = (x - u).pow(2).mean(1, keepdim=True)\n",
    "            x = (x - u) / torch.sqrt(s + self.eps)\n",
    "            x = self.weight[:, None, None] * x + self.bias[:, None, None]\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConvNeXt Block (2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeXtBlock(nn.Module):\n",
    "    def __init__(self, dim, layer_scale_init_value=1e-6):\n",
    "        super().__init__()\n",
    "        self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim) # depthwise conv\n",
    "        self.norm = LayerNorm(dim, eps=1e-6)\n",
    "        self.pwconv1 = nn.Linear(dim, 4 * dim) # pointwise/1x1 convs, implemented with linear layers\n",
    "        self.act = nn.GELU()\n",
    "        self.pwconv2 = nn.Linear(4 * dim, dim)\n",
    "        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim)), \n",
    "                                    requires_grad=True) if layer_scale_init_value > 0 else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x\n",
    "        x = self.dwconv(x)\n",
    "        x = x.permute(0, 2, 3, 1) # (B, C, H, W) -> (B, H, W, C)\n",
    "        x = self.norm(x)\n",
    "        x = self.pwconv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pwconv2(x)\n",
    "        if self.gamma is not None:\n",
    "            x = self.gamma * x\n",
    "        x = x.permute(0, 3, 1, 2) # (B, H, W, C) -> (B, C, H, W)\n",
    "\n",
    "        x = input + x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "      Layer (type)         Output Shape         Param #     Tr. Param #\n",
      "========================================================================\n",
      "          Conv2d-1      [1, 96, 16, 16]           4,800           4,800\n",
      "       LayerNorm-2      [1, 16, 16, 96]             192             192\n",
      "          Linear-3     [1, 16, 16, 384]          37,248          37,248\n",
      "            GELU-4     [1, 16, 16, 384]               0               0\n",
      "          Linear-5      [1, 16, 16, 96]          36,960          36,960\n",
      "========================================================================\n",
      "Total params: 79,200\n",
      "Trainable params: 79,200\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------\n",
      "input: torch.Size([1, 96, 16, 16])\n",
      "output: torch.Size([1, 96, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "x=torch.zeros(1,96,16,16).cuda() # [B,C,H,W] input: 16 x 16 x 96\n",
    "model=NeXtBlock(dim=96).to(device)\n",
    "\n",
    "print(summary(model,x))\n",
    "print('input:',x.shape)\n",
    "print('output:',model(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConvNeXt Block (3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeXtBlock3D(nn.Module):\n",
    "    def __init__(self, dim, layer_scale_init_value=1e-6):\n",
    "        super().__init__()\n",
    "        self.dwconv = nn.Conv3d(dim, dim, kernel_size=7, padding=3, groups=dim) # depthwise conv\n",
    "        self.norm = LayerNorm(dim, eps=1e-6)\n",
    "        self.pwconv1 = nn.Linear(dim, 4 * dim) # pointwise/1x1 convs, implemented with linear layers\n",
    "        self.act = nn.GELU()\n",
    "        self.pwconv2 = nn.Linear(4 * dim, dim)\n",
    "        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim)), \n",
    "                                    requires_grad=True) if layer_scale_init_value > 0 else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x\n",
    "        x = self.dwconv(x)\n",
    "        x = x.permute(0, 2, 3, 4, 1) # (B, C, D, H, W) -> (B, D, H, W, C)\n",
    "        x = self.norm(x)\n",
    "        x = self.pwconv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pwconv2(x)\n",
    "        if self.gamma is not None:\n",
    "            x = self.gamma * x\n",
    "        x = x.permute(0, 4, 1, 2, 3) # (B, D, H, W, C) -> (B, C, D, H, W)\n",
    "\n",
    "        x = input + x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "      Layer (type)             Output Shape         Param #     Tr. Param #\n",
      "============================================================================\n",
      "          Conv3d-1      [1, 96, 16, 16, 16]          33,024          33,024\n",
      "       LayerNorm-2      [1, 16, 16, 16, 96]             192             192\n",
      "          Linear-3     [1, 16, 16, 16, 384]          37,248          37,248\n",
      "            GELU-4     [1, 16, 16, 16, 384]               0               0\n",
      "          Linear-5      [1, 16, 16, 16, 96]          36,960          36,960\n",
      "============================================================================\n",
      "Total params: 107,424\n",
      "Trainable params: 107,424\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------------------\n",
      "input: torch.Size([1, 96, 16, 16, 16])\n",
      "output: torch.Size([1, 96, 16, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "x=torch.zeros(1,96,16, 16, 16).cuda() # [B,C,H,W] input: 16 x 16 x 16 x 96\n",
    "model=NeXtBlock3D(dim=96).to(device)\n",
    "\n",
    "print(summary(model,x))\n",
    "print('input:',x.shape)\n",
    "print('output:',model(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SerialAttn(nn.Module):\n",
    "    '''\n",
    "    Serialized Attention\n",
    "    '''\n",
    "    def __init__(self, input_size, hidden_size, proj_size, num_heads=4, qkv_bias=False,\n",
    "                 channel_attn_drop=0.1, spatial_attn_drop=0.1):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.temperature = nn.Parameter(torch.ones(num_heads, 1, 1)) # for channel attention\n",
    "        self.temperature2 = nn.Parameter(torch.ones(num_heads, 1, 1)) # for spatial attention\n",
    "\n",
    "        # qkv are 3 linear layers (query, key, value)\n",
    "        self.qkv = nn.Linear(hidden_size, hidden_size * 3, bias=qkv_bias)\n",
    "        self.qkv2 = nn.Linear(hidden_size, hidden_size * 3, bias=qkv_bias)\n",
    "\n",
    "        # projection matrices with shared weights used in attention module to project\n",
    "        self.proj_k = self.proj_v = nn.Linear(input_size, proj_size)\n",
    "\n",
    "        self.attn_drop = nn.Dropout(channel_attn_drop) \n",
    "        self.attn_drop_2 = nn.Dropout(spatial_attn_drop)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape # N=HWD\n",
    "        \n",
    "        '''\n",
    "        Spatial Attention\n",
    "        : K -> K(p), V -> V(p) [ Q x K_T(p) ]\n",
    "        '''\n",
    "        qkv2 = self.qkv2(x).reshape(B, N, 3, self.num_heads, C // self.num_heads) # B x N x 3 x h x C/h\n",
    "        qkv2 = qkv2.permute(2, 0, 3, 1, 4) # 3 x B x h x N x C/h\n",
    "        q2, k2, v2 = qkv2[0], qkv2[1], qkv2[2] # B x h x N x C/h\n",
    "\n",
    "        q2_t = q2.transpose(-2, -1) # B x h x C/h x N\n",
    "        k2_t = k2.transpose(-2, -1) # B x h x C/h x N\n",
    "        v2_t = v2.transpose(-2, -1) # B x h x C/h x N\n",
    "\n",
    "        k2_t_projected = self.proj_k(k2_t) # B x h x C/h x p\n",
    "        v2_t_projected = self.proj_v(v2_t) # B x h x C/h x p\n",
    "\n",
    "        q2_t = torch.nn.functional.normalize(q2_t, dim=-1)\n",
    "        k2_t = torch.nn.functional.normalize(k2_t, dim=-1)\n",
    "\n",
    "        q2 = q2_t.permute(0, 1, 3, 2) # Q : B x h x N x C/h\n",
    "        attn_SA = (q2 @ k2_t_projected) * self.temperature2  # [Q x K_T(p)] B x h x N x p\n",
    "        \n",
    "        attn_SA = attn_SA.softmax(dim=-1)\n",
    "        attn_SA = self.attn_drop_2(attn_SA) # [Spatial Attn Map] B x h x N x p\n",
    "        \n",
    "        v2_projected = v2_t_projected.transpose(-2, -1) # V(p) : B x h x p x C/h\n",
    "\n",
    "        # [Spatial Attn Map x V(p)] B x h x N x C/h -> B x C/h x h x N -> B x N x C\n",
    "        x_SA = (attn_SA @ v2_projected).permute(0, 3, 1, 2).reshape(B, N, C) \n",
    "        \n",
    "        '''\n",
    "        Channel Attention\n",
    "        : [ Q_T x K ]\n",
    "        '''\n",
    "        qkv = self.qkv(x_SA).reshape(B, N, 3, self.num_heads, C // self.num_heads) # B x N x 3 x h x C/h\n",
    "        qkv = qkv.permute(2, 0, 3, 1, 4) # 3 x B x h x N x C/h\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2] # B x h x N x C/h\n",
    "\n",
    "        q_t = q.transpose(-2, -1) # B x h x C/h x N\n",
    "        k_t = k.transpose(-2, -1) # B x h x C/h x N\n",
    "        v_t = v.transpose(-2, -1) # B x h x C/h x N\n",
    "\n",
    "        q_t = torch.nn.functional.normalize(q_t, dim=-1)\n",
    "        k_t = torch.nn.functional.normalize(k_t, dim=-1)\n",
    "        \n",
    "        k = k_t.transpose(-2, -1) # K : B x h x C/h x C/h\n",
    "        attn_CA = (q_t @ k) * self.temperature # [Q_T x K] B x h x C/h x C/h \n",
    "\n",
    "        attn_CA = attn_CA.softmax(dim=-1)\n",
    "        attn_CA = self.attn_drop(attn_CA) # [Channel Attn Map] B x h x C/h x C/h\n",
    "\n",
    "        v = v_t.permute(0,1,3,2) # V : B x h x N x C/h\n",
    "\n",
    "        # [V x Channel Attn Map] B x h x N x C/h -> B x C/h x h x N -> B x N x C\n",
    "        x_CA = (v @ attn_CA).permute(0, 3, 1, 2).reshape(B, N, C)\n",
    "        x = x_CA\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAB(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_size: int,\n",
    "            hidden_size: int,\n",
    "            proj_size: int,\n",
    "            num_heads: int,\n",
    "            dropout_rate: float = 0.0,\n",
    "            pos_embed=False,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.pos_embed = None\n",
    "        if pos_embed:\n",
    "            self.pos_embed = nn.Parameter(torch.zeros(1, input_size, hidden_size))\n",
    "\n",
    "        self.norm = nn.LayerNorm(hidden_size)\n",
    "        self.gamma = nn.Parameter(1e-6 * torch.ones(hidden_size), requires_grad=True)\n",
    "        self.MSA = SerialAttn(input_size=input_size, hidden_size=hidden_size, proj_size=proj_size, num_heads=num_heads, channel_attn_drop=dropout_rate,spatial_attn_drop=dropout_rate)\n",
    "        self.NeXtBlock = NeXtBlock3D(dim = hidden_size)\n",
    "        self.conv = nn.Sequential(nn.Dropout3d(0.1, False), nn.Conv3d(hidden_size, hidden_size, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, D, H, W = x.shape\n",
    "\n",
    "        x = x.reshape(B, C, H * W * D).permute(0, 2, 1)\n",
    "\n",
    "        if self.pos_embed is not None:\n",
    "            x = x + self.pos_embed\n",
    "        attn = x + self.gamma * self.MSA(self.norm(x))\n",
    "\n",
    "        attn_skip = attn.reshape(B, D, H, W, C).permute(0, 4, 1, 2, 3)  # (B, C, D, H, W)\n",
    "        attn = self.NeXtBlock(attn_skip)\n",
    "        x = attn_skip + self.conv(attn)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "      Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "       LayerNorm-1         [1, 512, 128]             256             256\n",
      "      SerialAttn-2         [1, 512, 128]         131,144         131,144\n",
      "     NeXtBlock3D-3     [1, 128, 8, 8, 8]         176,128         176,128\n",
      "       Dropout3d-4     [1, 128, 8, 8, 8]               0               0\n",
      "          Conv3d-5     [1, 128, 8, 8, 8]          16,512          16,512\n",
      "=========================================================================\n",
      "Total params: 324,040\n",
      "Trainable params: 324,040\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n",
      "input: torch.Size([1, 128, 8, 8, 8])\n",
      "output: torch.Size([1, 128, 8, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "input_size=[32 * 32 * 32, 16 * 16 * 16, 8 * 8 * 8, 4 * 4 * 4]\n",
    "dims=[32, 64, 128, 256]\n",
    "proj_size =[64,64,64,32]\n",
    "depths=[3, 3, 3, 3]\n",
    "num_heads=4\n",
    "transformer_dropout_rate=0.15\n",
    "\n",
    "\n",
    "model=SAB(input_size=input_size[2], hidden_size=dims[2],  proj_size=proj_size[2], num_heads=num_heads, dropout_rate=transformer_dropout_rate, pos_embed=True)\n",
    "\n",
    "x=torch.zeros(1,128,8,8,8) # [B,C,D,H,W] input: 16 x 16 x 16 x 64\n",
    "print(summary(model,x))\n",
    "print('input:',x.shape)\n",
    "print('output:',model(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PatchMerging (3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchMerging3D(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        '''\n",
    "        we remove layer norm. because we use GroupNorm outside.\n",
    "        we assume that h,w,d are even numbers.\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.reduction = nn.Linear(8 * dim, 2 * dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: B,C,D,H,W\n",
    "        '''\n",
    "        x = x.permute(0,2,3,4,1) # [B, D, H, W, C]\n",
    "        \n",
    "        x0 = x[:, 0::2, 0::2, 0::2, :]\n",
    "        x1 = x[:, 1::2, 0::2, 0::2, :]\n",
    "        x2 = x[:, 0::2, 1::2, 0::2, :]\n",
    "        x3 = x[:, 0::2, 0::2, 1::2, :]\n",
    "        x4 = x[:, 1::2, 0::2, 1::2, :]\n",
    "        x5 = x[:, 0::2, 1::2, 0::2, :]\n",
    "        x6 = x[:, 0::2, 0::2, 1::2, :]\n",
    "        x7 = x[:, 1::2, 1::2, 1::2, :]\n",
    "        \n",
    "        x = torch.cat([x0, x1, x2, x3, x4, x5, x6, x7], -1)\n",
    "        x = self.reduction(x)\n",
    "        x = x.permute(0, 4, 1, 2, 3) # [B, C, D, H, W]\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "      Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Linear-1     [1, 8, 8, 8, 128]          65,536          65,536\n",
      "=========================================================================\n",
      "Total params: 65,536\n",
      "Trainable params: 65,536\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n",
      "input: torch.Size([1, 64, 16, 16, 16])\n",
      "output: torch.Size([1, 128, 8, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "x=torch.zeros(1,64,16,16,16) # [B,C,D,H,W] input: 16 x 16 x 16 x 64\n",
    "model=PatchMerging3D(dim=x.shape[1])\n",
    "\n",
    "print(summary(model,x))\n",
    "print('input:',x.shape)\n",
    "print('output:',model(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PatchExpanding (3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchExpanding3D(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.expand = nn.Linear(dim, 4 * dim, bias=False)\n",
    "\n",
    "    def forward(self, y):\n",
    "        \"\"\"\n",
    "        y: B,C,D,H,W\n",
    "        \"\"\"\n",
    "        y=y.permute(0,3,4,2,1) # [B, D, H, W, C]\n",
    "        B, D, H, W, C = y.size()\n",
    "\n",
    "        y=self.expand(y) # B, H, W, D, 4*C\n",
    "    \n",
    "        y=rearrange(y,'b d h w (p1 p2 p3 c)-> b (d p1) (h p2) (w p3) c', p1=2, p2=2, p3=2, c=C//2) # B, 2*D, 2*H, 2*W, C//2\n",
    "\n",
    "        y=y.permute(0,4,3,1,2) # B, C//2, 2*D, 2*H, 2*W\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "      Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Linear-1     [1, 8, 8, 8, 512]          65,536          65,536\n",
      "=========================================================================\n",
      "Total params: 65,536\n",
      "Trainable params: 65,536\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n",
      "input: torch.Size([1, 128, 8, 8, 8])\n",
      "output: torch.Size([1, 64, 16, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "y=torch.zeros(1,128,8,8,8) # [B,C,D,H,W] input: 8 x 8 x 8 x 128\n",
    "model=PatchExpanding3D(dim=y.shape[1])\n",
    "\n",
    "print(summary(model,y))\n",
    "print('input:',y.shape)\n",
    "print('output:',model(y).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Local Concat MFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALC_MFA(nn.Module):\n",
    "    def __init__(self,std_cnl): \n",
    "        super().__init__()\n",
    "        '''\n",
    "        std_cnl = standard_channel\n",
    "        ex) 256\n",
    "        '''\n",
    "        self.control=nn.ModuleList([])\n",
    "        for in_cnl in [32,64,128]: \n",
    "            itr=int(math.log2(std_cnl//in_cnl))\n",
    "            self.down_layer=nn.Sequential()\n",
    "            cnl=in_cnl\n",
    "            for i in range(itr):\n",
    "                # downsampling with Dilated Convolution\n",
    "                self.down_layer.add_module(f'downsample_{i+1}',nn.Conv3d(in_channels=cnl,out_channels=cnl*2,kernel_size=2,stride=2,padding=1,dilation=3))\n",
    "                cnl=cnl*2\n",
    "            self.control.append(self.down_layer)\n",
    "\n",
    "        self.NeXtBlock = NeXtBlock3D(dim = std_cnl)\n",
    "\n",
    "    def forward(self,standard,x1,x2,x3):\n",
    "        # control resolution and channel\n",
    "        x1 = self.control[0](x1)\n",
    "        x2 = self.control[1](x2)\n",
    "        x3 = self.control[2](x3)\n",
    "\n",
    "        # fusion\n",
    "        x = x1 + x2 + x3 + standard\n",
    "        x = self.NeXtBlock(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "      Layer (type)            Output Shape         Param #     Tr. Param #\n",
      "===========================================================================\n",
      "          Conv3d-1     [1, 64, 16, 16, 16]          16,448          16,448\n",
      "          Conv3d-2       [1, 128, 8, 8, 8]          65,664          65,664\n",
      "          Conv3d-3       [1, 256, 4, 4, 4]         262,400         262,400\n",
      "          Conv3d-4       [1, 128, 8, 8, 8]          65,664          65,664\n",
      "          Conv3d-5       [1, 256, 4, 4, 4]         262,400         262,400\n",
      "          Conv3d-6       [1, 256, 4, 4, 4]         262,400         262,400\n",
      "     NeXtBlock3D-7       [1, 256, 4, 4, 4]         614,400         614,400\n",
      "===========================================================================\n",
      "Total params: 1,549,376\n",
      "Trainable params: 1,549,376\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------\n",
      "input: torch.Size([1, 256, 4, 4, 4]) torch.Size([1, 32, 32, 32, 32]) torch.Size([1, 64, 16, 16, 16]) torch.Size([1, 128, 8, 8, 8])\n",
      "output: torch.Size([1, 256, 4, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "x1=torch.zeros(1,32,32,32,32)\n",
    "x2=torch.zeros(1,64,16,16,16)\n",
    "x3=torch.zeros(1,128,8,8,8)\n",
    "x4=torch.zeros(1,256,4,4,4)\n",
    "\n",
    "model=ALC_MFA(std_cnl=256)\n",
    "\n",
    "print(summary(model,x4,x1,x2,x3))\n",
    "print('input:',x4.shape,x1.shape,x2.shape,x3.shape)\n",
    "print('output:',model(x4,x1,x2,x3).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross MFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttnModule(nn.Module):\n",
    "    def __init__(self, N_1, N_2, proj_size, dim, mlp_dim, num_heads=4, attn_drop=0.1):\n",
    "        '''\n",
    "        N_1 = H_1 x W_1 x D_1\n",
    "        N_2 = H_2 x W_2 x D_2\n",
    "        dim = Channel\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.temperature = nn.Parameter(torch.ones(num_heads, 1, 1))\n",
    "\n",
    "        # qkv layer\n",
    "        self.q = nn.Linear(dim, dim)\n",
    "        self.kv = nn.Linear(dim, dim*2)\n",
    "\n",
    "        # projection layer\n",
    "        self.proj_k = self.proj_v = nn.Linear(N_2, proj_size)\n",
    "\n",
    "        # positional embedding layer \n",
    "        self.pos_embed_q = nn.Parameter(torch.zeros(1, N_1, dim))\n",
    "        self.pos_embed_k = nn.Parameter(torch.zeros(1, N_2, dim))\n",
    "\n",
    "        # Dropout\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "\n",
    "        # Feed Forward Network\n",
    "        self.ffn = nn.Sequential( \n",
    "            nn.Linear(dim, mlp_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(mlp_dim, dim),\n",
    "          )\n",
    "\n",
    "    def forward(self,x1,x2):\n",
    "        B, N_1, C = x1.size()\n",
    "        B, N_2, C = x2.size()\n",
    "\n",
    "        '''\n",
    "        Make Q, K, V\n",
    "        '''\n",
    "        q = q_skip = self.q(x1) # B x N_1 x C\n",
    "\n",
    "        kv = self.kv(x2).reshape(B,N_2,2,C).permute(2,0,1,3) # 2 x B x N_2 x C\n",
    "        k, v = kv[0], kv[1] # B x N_2 x C\n",
    "\n",
    "        '''\n",
    "        Add Positional Encoding\n",
    "        '''\n",
    "        q += self.pos_embed_q # B x N_1 x C\n",
    "        k += self.pos_embed_k # B x N_2 x C\n",
    "\n",
    "        '''\n",
    "        Multi-Head Cross-Attention\n",
    "        '''\n",
    "        # reshape q,k,v\n",
    "        q = q.reshape(B, N_1, self.num_heads, C // self.num_heads).permute(0, 2, 1, 3) # B x h x N_1 x C/h\n",
    "        k = k.reshape(B, N_2, self.num_heads, C // self.num_heads).permute(0, 2, 1, 3) # B x h x N_2 x C/h\n",
    "        v = v.reshape(B, N_2, self.num_heads, C // self.num_heads).permute(0, 2, 1, 3) # B x h x N_2 x C/h\n",
    "\n",
    "        k_t = k.transpose(-2,-1) # B x h x C/h x N_2\n",
    "        v_t = v.transpose(-2,-1) # B x h x C/h x N_2\n",
    "\n",
    "        k_t_projected = self.proj_k(k_t) # B x h x C/h x p\n",
    "        v_t_projected = self.proj_v(v_t) # B x h x C/h x p\n",
    "\n",
    "        attn = (q @ k_t_projected) * self.temperature # [Q x K_t(p)] B x h x N_1 x p\n",
    "\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        v_projected = v_t_projected.transpose(-2,-1) # B x h x p x C/h\n",
    "\n",
    "        # [Attn Map x V(p)] B x h x N_1 x C/h -> B x C/h x h x N_1 -> B x N_1 x C\n",
    "        x = (attn @ v_projected).permute(0, 3, 1, 2).reshape(B, N_1, C) \n",
    "\n",
    "        '''\n",
    "        Add & Norm\n",
    "        '''\n",
    "        x += q_skip # B x N_1 X C\n",
    "        x = x_save = torch.nn.functional.normalize(x, dim=-1) # B x N_1 x C\n",
    "\n",
    "        '''\n",
    "        FFN -> Add & Norm\n",
    "        '''\n",
    "        x = self.ffn(x)\n",
    "        x += x_save\n",
    "        x = torch.nn.functional.normalize(x, dim=-1) # B x N_1 x C\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossMFA(nn.Module):\n",
    "    def __init__(self, HWD_l, HWD_g, proj_l, proj_g, dim_l, dim_g, itr):\n",
    "        super().__init__()\n",
    "        self.N_l = HWD_l\n",
    "        self.N_g = HWD_g\n",
    "        self.proj_l = proj_l\n",
    "        self.proj_g = proj_g\n",
    "        self.dim_l = dim_l\n",
    "        self.dim_g = dim_g\n",
    "        self.itr = itr\n",
    "\n",
    "        # dim_l = local feature map channel (32,64,128)\n",
    "        # dim_g = global feature map channel (64,128,256)\n",
    "\n",
    "        self.linear_g = nn.Linear(dim_g, dim_l)\n",
    "\n",
    "        self.crossAttn1Set = nn.ModuleList([])\n",
    "        for _ in range(self.itr):\n",
    "            self.crossAttn1Set.append(\n",
    "                CrossAttnModule(N_1=self.N_l, N_2=self.N_g, proj_size=self.proj_g, dim=self.dim_l, mlp_dim=self.dim_l*2) # Q: Local Feature, K,V: Global Feature)\n",
    "            )\n",
    "\n",
    "        self.crossAttn2Set = nn.ModuleList([])\n",
    "        for _ in range(self.itr):\n",
    "            self.crossAttn2Set.append(\n",
    "                CrossAttnModule(N_1=self.N_g, N_2=self.N_l, proj_size=self.proj_l, dim=self.dim_l, mlp_dim=self.dim_l*2) # Q: Global Feature, K,V: Local Feature\n",
    "            )\n",
    "\n",
    "        self.upsample = nn.ConvTranspose3d(in_channels=dim_l,out_channels=dim_l,kernel_size=2,stride=2)\n",
    "        self.NeXtBlock = NeXtBlock3D(dim = dim_l)\n",
    "\n",
    "    def forward(self,lf, gf):\n",
    "        '''\n",
    "        lf: local feature \n",
    "        ex) 32 x 32 x 32 x 32, 16 x 16 x 16 x 64, 8 x 8 x 8 x 128\n",
    "\n",
    "        fg: global feature\n",
    "        ex) 16 x 16 x 16 x 64, 8 x 8 x 8 x 128, 4 x 4 x 4 x 256\n",
    "        '''\n",
    "        # save local feature\n",
    "        lf_save = lf\n",
    "\n",
    "        # 4D -> 2D\n",
    "        B, C_l, D_l, H_l, W_l = lf.size()\n",
    "        lf = lf.view(B, C_l, D_l * H_l * W_l).permute(0,2,1) # B, HWD_l, C_l\n",
    "\n",
    "        B, C_g, D_g, H_g, W_g = gf.size()\n",
    "        gf = gf.view(B, C_g, D_g * H_g * W_g).permute(0,2,1) # B, HWD_g, C_g\n",
    "\n",
    "        # channel unify\n",
    "        gf = self.linear_g(gf) # B, HWD_g, C_l\n",
    "\n",
    "        '''\n",
    "        lf: local feature (reshaped)\n",
    "        ex) 32*32*32 x 32, 16*16*16 x 64, 8*8*8 x 128\n",
    "\n",
    "        gf: global feature (reshaped)\n",
    "        ex) 16*16x16 x 32, 8*8*8 x 64, 4*4*4 x 128\n",
    "        '''\n",
    "\n",
    "        # Double Cross Attn x itr\n",
    "        in_1, in_2 = lf, gf\n",
    "        for i in range(self.itr):\n",
    "            in_1 = out_1 = self.crossAttn1Set[i](in_1, in_2) # B, HWD_l, C_l \n",
    "            in_2 = out_2 = self.crossAttn2Set[i](in_2, in_1) # B, HWD_g, C_l\n",
    "\n",
    "        # 2D -> 4D\n",
    "        out_1_4d = out_1.reshape(B, D_l, H_l, W_l, C_l).permute(0, 4, 1, 2, 3) # B, C_l, D_l, H_l, W_l\n",
    "        out_2_4d = out_2.reshape(B, D_g, H_g, W_g, C_l).permute(0, 4, 1, 2, 3) # B, C_l, D_g, H_g, W_g\n",
    "\n",
    "        # Final Fusion with ConvNeXt Block\n",
    "        last_in = out_1_4d + self.upsample(out_2_4d)\n",
    "        out = self.NeXtBlock(last_in) # B, C_l, D_l, H_l, W_l\n",
    "\n",
    "        # skip connection\n",
    "        out += lf_save # B, C_l, D_l, H_l, W_l\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------\n",
      "        Layer (type)            Output Shape         Param #     Tr. Param #\n",
      "=============================================================================\n",
      "            Linear-1            [1, 512, 64]           8,256           8,256\n",
      "   CrossAttnModule-2           [1, 4096, 64]         356,804         356,804\n",
      "   CrossAttnModule-3            [1, 512, 64]         717,284         717,284\n",
      "   CrossAttnModule-4           [1, 4096, 64]         356,804         356,804\n",
      "   CrossAttnModule-5            [1, 512, 64]         717,284         717,284\n",
      "   CrossAttnModule-6           [1, 4096, 64]         356,804         356,804\n",
      "   CrossAttnModule-7            [1, 512, 64]         717,284         717,284\n",
      "   ConvTranspose3d-8     [1, 64, 16, 16, 16]          32,832          32,832\n",
      "       NeXtBlock3D-9     [1, 64, 16, 16, 16]          55,296          55,296\n",
      "=============================================================================\n",
      "Total params: 3,318,648\n",
      "Trainable params: 3,318,648\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------------\n",
      "input: torch.Size([1, 64, 16, 16, 16]) torch.Size([1, 128, 8, 8, 8])\n",
      "output: torch.Size([1, 64, 16, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "x1=torch.zeros(1,64,16,16,16) \n",
    "x2=torch.zeros(1,128,8,8,8) \n",
    "\n",
    "HWD_l = x1.shape[2]*x1.shape[3]*x1.shape[4]\n",
    "HWD_g = x2.shape[2]*x2.shape[3]*x2.shape[4]\n",
    "'''\n",
    "H x W x D = 32 x 32 x 32 -> proj_size = 128\n",
    "H x W x D = 16 x 16 x 16 -> proj_size = 96\n",
    "H x W x D = 8 x 8 x 8 -> proj_size = 64\n",
    "H x W x D = 4 x 4 x 4 -> proj_size = 32\n",
    "'''\n",
    "proj_l = 96\n",
    "proj_g = 64\n",
    "dim_l = x1.shape[1]\n",
    "dim_g = x2.shape[1]\n",
    "itr = 3 \n",
    "\n",
    "model=CrossMFA(HWD_l,HWD_g,proj_l,proj_g,dim_l,dim_g,itr)\n",
    "\n",
    "print(summary(model,x1,x2))\n",
    "print('input:',x1.shape,x2.shape)\n",
    "print('output:',model(x1,x2).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross MFA (원조: Transformer Tracking - CFA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossMFA(nn.Module):\n",
    "    def __init__(self, HWD_l, HWD_g, proj_l, proj_g, dim_l, dim_g, itr):\n",
    "        super().__init__()\n",
    "        self.N_l = HWD_l\n",
    "        self.N_g = HWD_g\n",
    "        self.proj_l = proj_l\n",
    "        self.proj_g = proj_g\n",
    "        self.dim_l = dim_l\n",
    "        self.dim_g = dim_g\n",
    "        self.itr = itr\n",
    "\n",
    "        # dim_l = local feature map channel (32,64,128)\n",
    "        # dim_g = global feature map channel (64,128,256)\n",
    "\n",
    "        self.linear_g = nn.Linear(dim_g, dim_l)\n",
    "\n",
    "\n",
    "        self.crossAttn1Set = nn.ModuleList([])\n",
    "        for _ in range(self.itr):\n",
    "            self.crossAttn1Set.append(\n",
    "                CrossAttnModule(N_1=self.N_l, N_2=self.N_g, proj_size=self.proj_g, dim=self.dim_l, mlp_dim=self.dim_l*2) # Q: Local Feature, K,V: Global Feature)\n",
    "            )\n",
    "\n",
    "        self.crossAttn2Set = nn.ModuleList([])\n",
    "        for _ in range(self.itr):\n",
    "            self.crossAttn2Set.append(\n",
    "                CrossAttnModule(N_1=self.N_g, N_2=self.N_l, proj_size=self.proj_l, dim=self.dim_l, mlp_dim=self.dim_l*2) # Q: Global Feature, K,V: Local Feature\n",
    "            )\n",
    "\n",
    "        self.crossAttnF = CrossAttnModule(N_1=self.N_l, N_2=self.N_g, proj_size=self.proj_g, dim=self.dim_l, mlp_dim=self.dim_l*2) # Q: Fusion Feature1, K,V: Fusion Feature2\n",
    "\n",
    "    def forward(self,lf, gf):\n",
    "        '''\n",
    "        lf: local feature \n",
    "        ex) 32 x 32 x 32 x 32, 16 x 16 x 16 x 64, 8 x 8 x 8 x 128\n",
    "\n",
    "        fg: global feature\n",
    "        ex) 16 x 16 x 16 x 64, 8 x 8 x 8 x 128, 4 x 4 x 4 x 256\n",
    "        '''\n",
    "        # 4D -> 2D\n",
    "        B_l, C_l, D_l, H_l, W_l = lf.size()\n",
    "        lf = lf.view(B_l, C_l, D_l * H_l * W_l).permute(0,2,1) # B, HWD_l, C_l\n",
    "\n",
    "        B_g, C_g, D_g, H_g, W_g = gf.size()\n",
    "        gf = gf.view(B_g, C_g, D_g * H_g * W_g).permute(0,2,1) # B, HWD_g, C_g\n",
    "\n",
    "        # channel unify\n",
    "        gf = self.linear_g(gf) # B, HWD_g, C_l\n",
    "\n",
    "        '''\n",
    "        lf: local feature (reshaped)\n",
    "        ex) 32*32*32 x 32, 16*16*16 x 64, 8*8*8 x 128\n",
    "\n",
    "        gf: global feature (reshaped)\n",
    "        ex) 16*16x16 x 32, 8*8*8 x 64, 4*4*4 x 128\n",
    "        '''\n",
    "\n",
    "        # Double Cross Attn x itr\n",
    "        in_1, in_2 = lf, gf\n",
    "        for i in range(self.itr):\n",
    "            in_1 = out_1 = self.crossAttn1Set[i](in_1, in_2) # B, HWD_l, C_l \n",
    "            in_2 = out_2 = self.crossAttn2Set[i](in_2, in_1) # B, HWD_g, C_l\n",
    "\n",
    "        # Final Cross Attn\n",
    "        out = self.crossAttnF(out_1,out_2) # B, HWD_l, C_l \n",
    "\n",
    "        # 2D -> 4D\n",
    "        out = out.reshape(B_l, D_l, H_l, W_l, C_l).permute(0, 4, 1, 2, 3) # B, C_l, D_l, H_l, W_l\n",
    "        \n",
    "        return out\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
