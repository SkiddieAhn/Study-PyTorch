{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training\n",
    "- ltr/run_training.py를 이용해서 학습 가능\n",
    "- ltr/admin/local.py에 dataset 경로를 기록해야 됨 (train 경로를 가리키게)\n",
    "- ltr/train_settings/transt/transt.py를 수정해서 커스터마이징 (배치 사이즈, 데이터셋 등)\n",
    "- 원래는 Lasot, Got10k, TrackingNet, MSCOCO 데이터로 학습 -> Got10k로만 학습\n",
    "\n",
    "ex) python run_training.py transt transt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  transt  transt\n",
      "=========================================\n",
      "DataLoader ok!!\n",
      "=========================================\n",
      "Loaded pretrained weights for efficientnet-b2\n",
      "=========================================\n",
      "model load ok!!\n",
      "=========================================\n",
      "number of params: 22037768\n",
      "=========================================\n",
      "Training Log PATH <tensorboard>\n",
      "/home/ahnsunghyun/pytorch/VisualTracking/TransT/checkpoints/tensorboard/ltr/transt/transt\n",
      "=========================================\n",
      "2022-06-24 13:55:37.708027: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "=========================================\n",
      "Training Start!!\n",
      "=========================================\n",
      "No matching checkpoint file found\n",
      "Training crashed at epoch 1\n",
      "Traceback for the error!\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/trainers/base_trainer.py\", line 70, in train\n",
      "    self.train_epoch()\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/trainers/ltr_trainer.py\", line 83, in train_epoch\n",
      "    self.cycle_dataset(loader)\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/trainers/ltr_trainer.py\", line 64, in cycle_dataset\n",
      "    loss, stats = self.actor(data)\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/actors/tracking.py\", line 17, in __call__\n",
      "    outputs = self.net(data['search_images'], data['template_images'])\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 165, in forward\n",
      "    return self.module(*inputs[0], **kwargs[0])\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/models/tracking/transt.py\", line 53, in forward\n",
      "    feature_search, pos_search = self.backbone(search)\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/models/backbone/transt_backbone.py\", line 100, in forward\n",
      "    xs = self[0](tensor_list)\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/models/backbone/transt_backbone.py\", line 66, in forward\n",
      "    for name, x in xs.items():\n",
      "AttributeError: 'Tensor' object has no attribute 'items'\n",
      "\n",
      "Restarting training from last epoch ...\n",
      "No matching checkpoint file found\n",
      "Training crashed at epoch 1\n",
      "Traceback for the error!\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/trainers/base_trainer.py\", line 70, in train\n",
      "    self.train_epoch()\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/trainers/ltr_trainer.py\", line 83, in train_epoch\n",
      "    self.cycle_dataset(loader)\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/trainers/ltr_trainer.py\", line 64, in cycle_dataset\n",
      "    loss, stats = self.actor(data)\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/actors/tracking.py\", line 17, in __call__\n",
      "    outputs = self.net(data['search_images'], data['template_images'])\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 165, in forward\n",
      "    return self.module(*inputs[0], **kwargs[0])\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/models/tracking/transt.py\", line 53, in forward\n",
      "    feature_search, pos_search = self.backbone(search)\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/models/backbone/transt_backbone.py\", line 100, in forward\n",
      "    xs = self[0](tensor_list)\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/models/backbone/transt_backbone.py\", line 66, in forward\n",
      "    for name, x in xs.items():\n",
      "AttributeError: 'Tensor' object has no attribute 'items'\n",
      "\n",
      "Restarting training from last epoch ...\n",
      "No matching checkpoint file found\n",
      "Training crashed at epoch 1\n",
      "Traceback for the error!\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/trainers/base_trainer.py\", line 70, in train\n",
      "    self.train_epoch()\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/trainers/ltr_trainer.py\", line 83, in train_epoch\n",
      "    self.cycle_dataset(loader)\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/trainers/ltr_trainer.py\", line 64, in cycle_dataset\n",
      "    loss, stats = self.actor(data)\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/actors/tracking.py\", line 17, in __call__\n",
      "    outputs = self.net(data['search_images'], data['template_images'])\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 165, in forward\n",
      "    return self.module(*inputs[0], **kwargs[0])\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/models/tracking/transt.py\", line 53, in forward\n",
      "    feature_search, pos_search = self.backbone(search)\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/models/backbone/transt_backbone.py\", line 100, in forward\n",
      "    xs = self[0](tensor_list)\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/models/backbone/transt_backbone.py\", line 66, in forward\n",
      "    for name, x in xs.items():\n",
      "AttributeError: 'Tensor' object has no attribute 'items'\n",
      "\n",
      "Restarting training from last epoch ...\n",
      "No matching checkpoint file found\n",
      "Training crashed at epoch 1\n",
      "Traceback for the error!\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/trainers/base_trainer.py\", line 70, in train\n",
      "    self.train_epoch()\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/trainers/ltr_trainer.py\", line 83, in train_epoch\n",
      "    self.cycle_dataset(loader)\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/trainers/ltr_trainer.py\", line 64, in cycle_dataset\n",
      "    loss, stats = self.actor(data)\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/actors/tracking.py\", line 17, in __call__\n",
      "    outputs = self.net(data['search_images'], data['template_images'])\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 165, in forward\n",
      "    return self.module(*inputs[0], **kwargs[0])\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/models/tracking/transt.py\", line 53, in forward\n",
      "    feature_search, pos_search = self.backbone(search)\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/models/backbone/transt_backbone.py\", line 100, in forward\n",
      "    xs = self[0](tensor_list)\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/models/backbone/transt_backbone.py\", line 66, in forward\n",
      "    for name, x in xs.items():\n",
      "AttributeError: 'Tensor' object has no attribute 'items'\n",
      "\n",
      "Restarting training from last epoch ...\n",
      "No matching checkpoint file found\n",
      "Training crashed at epoch 1\n",
      "Traceback for the error!\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/trainers/base_trainer.py\", line 70, in train\n",
      "    self.train_epoch()\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/trainers/ltr_trainer.py\", line 83, in train_epoch\n",
      "    self.cycle_dataset(loader)\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/trainers/ltr_trainer.py\", line 64, in cycle_dataset\n",
      "    loss, stats = self.actor(data)\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/actors/tracking.py\", line 17, in __call__\n",
      "    outputs = self.net(data['search_images'], data['template_images'])\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 165, in forward\n",
      "    return self.module(*inputs[0], **kwargs[0])\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/models/tracking/transt.py\", line 53, in forward\n",
      "    feature_search, pos_search = self.backbone(search)\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/models/backbone/transt_backbone.py\", line 100, in forward\n",
      "    xs = self[0](tensor_list)\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/models/backbone/transt_backbone.py\", line 66, in forward\n",
      "    for name, x in xs.items():\n",
      "AttributeError: 'Tensor' object has no attribute 'items'\n",
      "\n",
      "Restarting training from last epoch ...\n",
      "No matching checkpoint file found\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "Training crashed at epoch 1\n",
      "Traceback for the error!\n",
      "  File \"/usr/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/data/__init__.py\", line 1, in <module>\n",
      "    from .loader import LTRLoader\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/data/loader.py\", line 6, in <module>\n",
      "    from pytracking import TensorDict, TensorList\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/pytracking/__init__.py\", line 7, in <module>\n",
      "    from pytracking.run_tracker import run_tracker\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/pytracking/run_tracker.py\", line 9, in <module>\n",
      "    from pytracking.evaluation import get_dataset\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/pytracking/evaluation/__init__.py\", line 2, in <module>\n",
      "    from .tracker import Tracker, trackerlist\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/pytracking/evaluation/tracker.py\", line 8, in <module>\n",
      "    from pytracking.utils.visdom import Visdom\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/pytracking/utils/visdom.py\", line 1, in <module>\n",
      "    import visdom\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/visdom/__init__.py\", line 44, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/trainers/base_trainer.py\", line 70, in train\n",
      "    self.train_epoch()\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/trainers/ltr_trainer.py\", line 83, in train_epoch\n",
      "    self.cycle_dataset(loader)\n",
      "  File \"/home/ahnsunghyun/pytorch/VisualTracking/TransT/ltr/trainers/ltr_trainer.py\", line 56, in cycle_dataset\n",
      "    for i, data in enumerate(loader, 1):\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 355, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 301, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 914, in __init__\n",
      "    w.start()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 121, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/context.py\", line 224, in _Popen\n",
      "    return _default_context.get_context().Process._Popen(process_obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/context.py\", line 284, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\n",
      "    super().__init__(process_obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/popen_fork.py\", line 19, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/popen_spawn_posix.py\", line 62, in _launch\n",
      "    f.write(fp.getbuffer())\n",
      "KeyboardInterrupt\n",
      "\n",
      "Restarting training from last epoch ...\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f1a7587a8b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1291, in _shutdown_workers\n",
      "    if self._persistent_workers or self._workers_status[worker_id]:\n",
      "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n",
      "No matching checkpoint file found\n",
      "    import bs4  # type: ignore\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/bs4/__init__.py\", line 38, in <module>\n",
      "    from .builder import builder_registry, ParserRejectedMarkup\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/bs4/builder/__init__.py\", line 7, in <module>\n",
      "    from bs4.element import (\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/bs4/element.py\", line 12, in <module>\n",
      "    import soupsieve\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/soupsieve/__init__.py\", line 29, in <module>\n",
      "    from . import css_parser as cp\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/soupsieve/css_parser.py\", line 1202, in <module>\n",
      "    CSS_DISABLED = CSSParser(\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/soupsieve/css_parser.py\", line 1159, in process_selectors\n",
      "    return self.parse_selectors(self.selector_iter(self.pattern), index, flags)\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/soupsieve/css_parser.py\", line 1113, in parse_selectors\n",
      "    return ct.SelectorList([s.freeze() for s in selectors], is_not, is_html)\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/soupsieve/css_parser.py\", line 1113, in <listcomp>\n",
      "    return ct.SelectorList([s.freeze() for s in selectors], is_not, is_html)\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/soupsieve/css_parser.py\", line 410, in freeze\n",
      "    self._freeze_relations(self.relations),\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/soupsieve/css_parser.py\", line 393, in _freeze_relations\n",
      "    return ct.SelectorList([sel.freeze()])\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/soupsieve/css_parser.py\", line 410, in freeze\n",
      "    self._freeze_relations(self.relations),\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/soupsieve/css_parser.py\", line 393, in _freeze_relations\n",
      "    return ct.SelectorList([sel.freeze()])\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/soupsieve/css_parser.py\", line 403, in freeze\n",
      "    return ct.Selector(\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/soupsieve/css_types.py\", line 219, in __init__\n",
      "    super().__init__(\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/soupsieve/css_types.py\", line 48, in __init__\n",
      "    super(Immutable, self).__setattr__('_hash', hash(tuple(temp)))\n",
      "  File \"/home/ahnsunghyun/.local/lib/python3.8/site-packages/soupsieve/css_types.py\", line 72, in __hash__\n",
      "    def __hash__(self) -> int:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!cd ~/pytorch/VisualTracking/TransT\n",
    "!python3 ltr/run_training.py transt transt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test\n",
    "- pysot_toolkit/test.py를 이용해서 평가 가능\n",
    "- test.py에 dataset_root과 net_path를 기록해야 됨\n",
    "\n",
    "ex) python -u pysot_toolkit/test.py --dataset <name of dataset> --name 'transt' #test tracker #test tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ahnsunghyun/pytorch/VisualTracking/TransT\n",
      "pysot_toolkit/..\n",
      "loading GOT-10k: 100%|███████████████████████| 180/180 [00:02<00:00, 85.69it/s, GOT-10k_Test_000180]\n",
      "(  1) Video: GOT-10k_Test_000001 Time:   6.7s Speed: 14.7fps\n",
      "(  2) Video: GOT-10k_Test_000002 Time:   2.9s Speed: 27.3fps\n",
      "(  3) Video: GOT-10k_Test_000003 Time:   2.4s Speed: 33.5fps\n",
      "(  4) Video: GOT-10k_Test_000004 Time:   2.1s Speed: 33.8fps\n",
      "(  5) Video: GOT-10k_Test_000005 Time:   2.1s Speed: 31.5fps\n",
      "(  6) Video: GOT-10k_Test_000006 Time:   3.1s Speed: 31.6fps\n",
      "(  7) Video: GOT-10k_Test_000007 Time:   3.0s Speed: 33.2fps\n",
      "(  8) Video: GOT-10k_Test_000008 Time:   3.2s Speed: 30.6fps\n",
      "(  9) Video: GOT-10k_Test_000009 Time:   2.9s Speed: 32.6fps\n",
      "( 10) Video: GOT-10k_Test_000010 Time:   3.1s Speed: 32.0fps\n",
      "( 11) Video: GOT-10k_Test_000011 Time:   3.7s Speed: 17.3fps\n",
      "( 12) Video: GOT-10k_Test_000012 Time:   3.7s Speed: 21.1fps\n",
      "( 13) Video: GOT-10k_Test_000013 Time:   2.3s Speed: 30.5fps\n",
      "( 14) Video: GOT-10k_Test_000014 Time:   3.0s Speed: 26.8fps\n",
      "( 15) Video: GOT-10k_Test_000015 Time:   2.5s Speed: 31.1fps\n",
      "( 16) Video: GOT-10k_Test_000016 Time:   2.2s Speed: 31.5fps\n",
      "( 17) Video: GOT-10k_Test_000017 Time:   2.4s Speed: 32.6fps\n",
      "( 18) Video: GOT-10k_Test_000018 Time:   2.9s Speed: 30.8fps\n",
      "( 19) Video: GOT-10k_Test_000019 Time:   2.4s Speed: 33.2fps\n",
      "( 20) Video: GOT-10k_Test_000020 Time:   3.0s Speed: 33.1fps\n",
      "( 21) Video: GOT-10k_Test_000021 Time:   1.9s Speed: 33.0fps\n",
      "( 22) Video: GOT-10k_Test_000022 Time:   3.7s Speed: 26.9fps\n",
      "( 23) Video: GOT-10k_Test_000023 Time:   3.3s Speed: 30.0fps\n",
      "( 24) Video: GOT-10k_Test_000024 Time:   3.0s Speed: 32.5fps\n",
      "( 25) Video: GOT-10k_Test_000025 Time:   2.9s Speed: 30.9fps\n",
      "( 26) Video: GOT-10k_Test_000026 Time:   2.6s Speed: 33.6fps\n",
      "( 27) Video: GOT-10k_Test_000027 Time:   3.0s Speed: 32.6fps\n",
      "( 28) Video: GOT-10k_Test_000028 Time:   3.2s Speed: 30.8fps\n",
      "( 29) Video: GOT-10k_Test_000029 Time:   3.1s Speed: 31.8fps\n",
      "( 30) Video: GOT-10k_Test_000030 Time:   3.0s Speed: 33.2fps\n",
      "( 31) Video: GOT-10k_Test_000031 Time:   2.9s Speed: 34.2fps\n",
      "( 32) Video: GOT-10k_Test_000032 Time:   2.9s Speed: 34.3fps\n",
      "( 33) Video: GOT-10k_Test_000033 Time:   1.7s Speed: 28.9fps\n",
      "( 34) Video: GOT-10k_Test_000034 Time:   2.4s Speed: 28.7fps\n",
      "( 35) Video: GOT-10k_Test_000035 Time:   2.3s Speed: 33.9fps\n",
      "( 36) Video: GOT-10k_Test_000036 Time:   2.6s Speed: 33.7fps\n",
      "( 37) Video: GOT-10k_Test_000037 Time:   3.6s Speed: 27.6fps\n",
      "( 38) Video: GOT-10k_Test_000038 Time:   3.4s Speed: 28.8fps\n",
      "( 39) Video: GOT-10k_Test_000039 Time:   3.1s Speed: 31.5fps\n",
      "( 40) Video: GOT-10k_Test_000040 Time:   4.1s Speed: 26.7fps\n",
      "( 41) Video: GOT-10k_Test_000041 Time:   2.6s Speed: 34.1fps\n",
      "( 42) Video: GOT-10k_Test_000042 Time:   2.9s Speed: 33.7fps\n",
      "( 43) Video: GOT-10k_Test_000043 Time:   2.9s Speed: 34.0fps\n",
      "( 44) Video: GOT-10k_Test_000044 Time:   3.0s Speed: 33.5fps\n",
      "( 45) Video: GOT-10k_Test_000045 Time:   2.9s Speed: 33.9fps\n",
      "( 46) Video: GOT-10k_Test_000046 Time:   3.0s Speed: 33.3fps\n",
      "( 47) Video: GOT-10k_Test_000047 Time:   3.0s Speed: 33.5fps\n",
      "( 48) Video: GOT-10k_Test_000048 Time:   3.0s Speed: 33.2fps\n",
      "( 49) Video: GOT-10k_Test_000049 Time:   8.0s Speed: 11.1fps\n",
      "( 50) Video: GOT-10k_Test_000050 Time:   2.4s Speed: 33.4fps\n",
      "( 51) Video: GOT-10k_Test_000051 Time:   3.5s Speed: 27.8fps\n",
      "( 52) Video: GOT-10k_Test_000052 Time:   2.1s Speed: 33.1fps\n",
      "( 53) Video: GOT-10k_Test_000053 Time:   2.0s Speed: 35.0fps\n",
      "( 54) Video: GOT-10k_Test_000054 Time:   2.4s Speed: 33.3fps\n",
      "( 55) Video: GOT-10k_Test_000055 Time:   2.6s Speed: 33.9fps\n",
      "( 56) Video: GOT-10k_Test_000056 Time:   3.7s Speed: 26.5fps\n",
      "( 57) Video: GOT-10k_Test_000057 Time:   3.1s Speed: 32.2fps\n",
      "( 58) Video: GOT-10k_Test_000058 Time:   3.0s Speed: 30.1fps\n",
      "( 59) Video: GOT-10k_Test_000059 Time:   2.1s Speed: 32.3fps\n",
      "( 60) Video: GOT-10k_Test_000060 Time:   4.4s Speed: 26.8fps\n",
      "( 61) Video: GOT-10k_Test_000061 Time:   3.6s Speed: 27.6fps\n",
      "( 62) Video: GOT-10k_Test_000062 Time:   3.0s Speed: 32.9fps\n",
      "( 63) Video: GOT-10k_Test_000063 Time:   2.5s Speed: 35.1fps\n",
      "( 64) Video: GOT-10k_Test_000064 Time:   7.2s Speed: 34.5fps\n",
      "( 65) Video: GOT-10k_Test_000065 Time:   2.7s Speed: 32.8fps\n",
      "( 66) Video: GOT-10k_Test_000066 Time:   3.6s Speed: 33.0fps\n",
      "( 67) Video: GOT-10k_Test_000067 Time:   2.8s Speed: 31.6fps\n",
      "( 68) Video: GOT-10k_Test_000068 Time:   3.1s Speed: 31.8fps\n",
      "( 69) Video: GOT-10k_Test_000069 Time:   3.2s Speed: 33.9fps\n",
      "( 70) Video: GOT-10k_Test_000070 Time:   4.8s Speed: 33.4fps\n",
      "( 71) Video: GOT-10k_Test_000071 Time:   3.6s Speed: 25.2fps\n",
      "( 72) Video: GOT-10k_Test_000072 Time:   2.9s Speed: 34.1fps\n",
      "( 73) Video: GOT-10k_Test_000073 Time:   2.7s Speed: 33.9fps\n",
      "( 74) Video: GOT-10k_Test_000074 Time:   3.7s Speed: 29.4fps\n",
      "( 75) Video: GOT-10k_Test_000075 Time:   3.9s Speed: 25.9fps\n",
      "( 76) Video: GOT-10k_Test_000076 Time:   3.6s Speed: 27.8fps\n",
      "( 77) Video: GOT-10k_Test_000077 Time:   3.5s Speed: 36.4fps\n",
      "( 78) Video: GOT-10k_Test_000078 Time:   2.2s Speed: 36.4fps\n",
      "( 79) Video: GOT-10k_Test_000079 Time:   3.9s Speed: 35.6fps\n",
      "( 80) Video: GOT-10k_Test_000080 Time:   3.4s Speed: 29.4fps\n",
      "( 81) Video: GOT-10k_Test_000081 Time:   3.2s Speed: 31.0fps\n",
      "( 82) Video: GOT-10k_Test_000082 Time:   2.3s Speed: 34.7fps\n",
      "( 83) Video: GOT-10k_Test_000083 Time:   2.3s Speed: 34.2fps\n",
      "( 84) Video: GOT-10k_Test_000084 Time:   1.8s Speed: 35.6fps\n",
      "( 85) Video: GOT-10k_Test_000085 Time:   6.9s Speed: 30.2fps\n",
      "( 86) Video: GOT-10k_Test_000086 Time:   5.0s Speed: 30.0fps\n",
      "( 87) Video: GOT-10k_Test_000087 Time:   2.6s Speed: 36.1fps\n",
      "( 88) Video: GOT-10k_Test_000088 Time:   1.9s Speed: 36.3fps\n",
      "( 89) Video: GOT-10k_Test_000089 Time:   3.8s Speed: 34.3fps\n",
      "( 90) Video: GOT-10k_Test_000090 Time:   2.8s Speed: 35.9fps\n",
      "( 91) Video: GOT-10k_Test_000091 Time:   8.2s Speed: 34.0fps\n",
      "( 92) Video: GOT-10k_Test_000092 Time:  30.0s Speed: 30.6fps\n",
      "( 93) Video: GOT-10k_Test_000093 Time:   2.9s Speed: 34.6fps\n",
      "( 94) Video: GOT-10k_Test_000094 Time:   2.3s Speed: 34.6fps\n",
      "( 95) Video: GOT-10k_Test_000095 Time:   2.9s Speed: 34.3fps\n",
      "( 96) Video: GOT-10k_Test_000096 Time:   2.8s Speed: 34.8fps\n",
      "( 97) Video: GOT-10k_Test_000097 Time:   2.4s Speed: 34.4fps\n",
      "( 98) Video: GOT-10k_Test_000098 Time:   3.2s Speed: 24.8fps\n",
      "( 99) Video: GOT-10k_Test_000099 Time:   3.2s Speed: 28.0fps\n",
      "(100) Video: GOT-10k_Test_000100 Time:   2.6s Speed: 34.1fps\n",
      "(101) Video: GOT-10k_Test_000101 Time:   2.5s Speed: 35.2fps\n",
      "(102) Video: GOT-10k_Test_000102 Time:   2.8s Speed: 35.7fps\n",
      "(103) Video: GOT-10k_Test_000103 Time:   1.9s Speed: 36.0fps\n",
      "(104) Video: GOT-10k_Test_000104 Time:   2.8s Speed: 35.3fps\n",
      "(105) Video: GOT-10k_Test_000105 Time:   2.7s Speed: 36.0fps\n",
      "(106) Video: GOT-10k_Test_000106 Time:   3.0s Speed: 33.5fps\n",
      "(107) Video: GOT-10k_Test_000107 Time:   3.5s Speed: 22.0fps\n",
      "(108) Video: GOT-10k_Test_000108 Time:   3.3s Speed: 30.2fps\n",
      "(109) Video: GOT-10k_Test_000109 Time:   2.2s Speed: 32.0fps\n",
      "(110) Video: GOT-10k_Test_000110 Time:   5.8s Speed: 11.9fps\n",
      "(111) Video: GOT-10k_Test_000111 Time:  12.9s Speed: 23.9fps\n",
      "(112) Video: GOT-10k_Test_000112 Time:   3.2s Speed: 30.4fps\n",
      "(113) Video: GOT-10k_Test_000113 Time:   2.8s Speed: 35.1fps\n",
      "(114) Video: GOT-10k_Test_000114 Time:   4.5s Speed: 24.5fps\n",
      "(115) Video: GOT-10k_Test_000115 Time:   5.1s Speed: 27.5fps\n",
      "(116) Video: GOT-10k_Test_000116 Time:   4.7s Speed: 33.7fps\n",
      "(117) Video: GOT-10k_Test_000117 Time:   9.6s Speed: 36.3fps\n",
      "(118) Video: GOT-10k_Test_000118 Time:   3.9s Speed: 18.1fps\n",
      "(119) Video: GOT-10k_Test_000119 Time:   2.1s Speed: 33.9fps\n",
      "(120) Video: GOT-10k_Test_000120 Time:   5.7s Speed: 34.9fps\n",
      "(121) Video: GOT-10k_Test_000121 Time:   5.3s Speed: 35.7fps\n",
      "(122) Video: GOT-10k_Test_000122 Time:   3.0s Speed: 32.9fps\n",
      "(123) Video: GOT-10k_Test_000123 Time:   2.7s Speed: 36.6fps\n",
      "(124) Video: GOT-10k_Test_000124 Time:   2.1s Speed: 37.7fps\n",
      "(125) Video: GOT-10k_Test_000125 Time:   1.9s Speed: 36.7fps\n",
      "(126) Video: GOT-10k_Test_000126 Time:   2.2s Speed: 36.7fps\n",
      "(127) Video: GOT-10k_Test_000127 Time:   1.9s Speed: 37.2fps\n",
      "(128) Video: GOT-10k_Test_000128 Time:   2.2s Speed: 36.4fps\n",
      "(129) Video: GOT-10k_Test_000129 Time:   3.3s Speed: 36.8fps\n",
      "(130) Video: GOT-10k_Test_000130 Time:   3.3s Speed: 36.8fps\n",
      "(131) Video: GOT-10k_Test_000131 Time:   3.8s Speed: 28.9fps\n",
      "(132) Video: GOT-10k_Test_000132 Time:   4.5s Speed: 17.9fps\n",
      "(133) Video: GOT-10k_Test_000133 Time:   7.9s Speed: 36.9fps\n",
      "(134) Video: GOT-10k_Test_000134 Time:   8.4s Speed: 36.7fps\n",
      "(135) Video: GOT-10k_Test_000135 Time:  13.4s Speed: 11.2fps\n",
      "(136) Video: GOT-10k_Test_000136 Time:   6.1s Speed: 28.7fps\n",
      "(137) Video: GOT-10k_Test_000137 Time:  14.1s Speed: 24.8fps\n",
      "(138) Video: GOT-10k_Test_000138 Time:  29.1s Speed: 7.5fps\n",
      "(139) Video: GOT-10k_Test_000139 Time:   4.6s Speed: 32.7fps\n",
      "(140) Video: GOT-10k_Test_000140 Time:   4.3s Speed: 32.3fps\n",
      "(141) Video: GOT-10k_Test_000141 Time:   2.9s Speed: 33.9fps\n",
      "(142) Video: GOT-10k_Test_000142 Time:   6.1s Speed: 36.0fps\n",
      "(143) Video: GOT-10k_Test_000143 Time:   2.2s Speed: 35.9fps\n",
      "(144) Video: GOT-10k_Test_000144 Time:   9.0s Speed: 33.3fps\n",
      "(145) Video: GOT-10k_Test_000145 Time:   6.7s Speed: 35.6fps\n",
      "(146) Video: GOT-10k_Test_000146 Time:   3.7s Speed: 35.2fps\n",
      "(147) Video: GOT-10k_Test_000147 Time:   4.8s Speed: 35.2fps\n",
      "(148) Video: GOT-10k_Test_000148 Time:   3.4s Speed: 33.9fps\n",
      "(149) Video: GOT-10k_Test_000149 Time:   5.5s Speed: 32.9fps\n",
      "(150) Video: GOT-10k_Test_000150 Time:  13.7s Speed: 35.7fps\n",
      "(151) Video: GOT-10k_Test_000151 Time:   7.0s Speed: 35.5fps\n",
      "(152) Video: GOT-10k_Test_000152 Time:   5.1s Speed: 35.5fps\n",
      "(153) Video: GOT-10k_Test_000153 Time:   2.8s Speed: 32.5fps\n",
      "(154) Video: GOT-10k_Test_000154 Time:   3.6s Speed: 24.9fps\n",
      "(155) Video: GOT-10k_Test_000155 Time:   8.5s Speed: 36.3fps\n",
      "(156) Video: GOT-10k_Test_000156 Time:   4.1s Speed: 31.2fps\n",
      "(157) Video: GOT-10k_Test_000157 Time:   7.2s Speed: 33.5fps\n",
      "(158) Video: GOT-10k_Test_000158 Time:   5.9s Speed: 35.5fps\n",
      "(159) Video: GOT-10k_Test_000159 Time:   2.8s Speed: 35.7fps\n",
      "(160) Video: GOT-10k_Test_000160 Time:  10.3s Speed: 35.0fps\n",
      "(161) Video: GOT-10k_Test_000161 Time:   5.9s Speed: 35.6fps\n",
      "(162) Video: GOT-10k_Test_000162 Time:   2.8s Speed: 35.6fps\n",
      "(163) Video: GOT-10k_Test_000163 Time:   3.7s Speed: 34.8fps\n",
      "(164) Video: GOT-10k_Test_000164 Time:  18.7s Speed: 36.3fps\n",
      "(165) Video: GOT-10k_Test_000165 Time:  25.0s Speed: 8.0fps\n",
      "(166) Video: GOT-10k_Test_000166 Time:   2.1s Speed: 33.1fps\n",
      "(167) Video: GOT-10k_Test_000167 Time:   2.8s Speed: 35.5fps\n",
      "(168) Video: GOT-10k_Test_000168 Time:   2.3s Speed: 35.2fps\n",
      "(169) Video: GOT-10k_Test_000169 Time:   2.5s Speed: 35.5fps\n",
      "(170) Video: GOT-10k_Test_000170 Time:   2.9s Speed: 31.2fps\n",
      "(171) Video: GOT-10k_Test_000171 Time:   2.5s Speed: 35.0fps\n",
      "(172) Video: GOT-10k_Test_000172 Time:   2.2s Speed: 36.2fps\n",
      "(173) Video: GOT-10k_Test_000173 Time:   2.3s Speed: 35.4fps\n",
      "(174) Video: GOT-10k_Test_000174 Time:   2.6s Speed: 34.1fps\n",
      "(175) Video: GOT-10k_Test_000175 Time:   2.5s Speed: 36.6fps\n",
      "(176) Video: GOT-10k_Test_000176 Time:   2.7s Speed: 36.5fps\n",
      "(177) Video: GOT-10k_Test_000177 Time:   3.0s Speed: 33.2fps\n",
      "(178) Video: GOT-10k_Test_000178 Time:   3.4s Speed: 34.9fps\n",
      "(179) Video: GOT-10k_Test_000179 Time:   2.7s Speed: 33.4fps\n",
      "(180) Video: GOT-10k_Test_000180 Time:   2.7s Speed: 29.5fps\n"
     ]
    }
   ],
   "source": [
    "# pre-trained된 transt 모델로 GOT-10k 테스트\n",
    "!cd TransT\n",
    "!python3 -u pysot_toolkit/test.py --dataset 'GOT-10k' --name 'transt' #test tracker #test tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation\n",
    "- pysot_toolkit/eval.py를 이용해서 평가 가능\n",
    "- OTB, LaSOT, UAV, NFS, VOT2016~2019만 평가 가능\n",
    "- GOT-10k를 평가하려면 got10k_toolkit을 참조\n",
    "\n",
    "ex) python pysot_toolkit/eval.py --tracker_path results/ --dataset <name of dataset> --num 1 --tracker_prefix 'transt' #eval tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd TransT"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
