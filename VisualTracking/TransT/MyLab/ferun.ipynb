{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TransT의 Feature Extractor 실행 구조\n",
    "\n",
    "1. run_training.py에서 settings 객체 생성, train_settings/transt/transt.py경로의 run함수 실행\n",
    "2. run 함수에서 settings 객체의 필드를 초기화, models/tracking/transt.py 경로의 transt_resnet50함수를 실행\n",
    "3. transt_resnet50함수에서 backbone을 불러오기 위해 models/backbone/transt_backbone.py 경로의 build_backbone함수를 실행\n",
    "4. build_backbone함수에서 backbone을 정의하기 위해 Backbone 클래스 생성자를 호출 (인스턴스화)\n",
    "5. Backbone 생성자에서 backbone을 생성하기 위해 models/backbone/resnet.py 경로의 resnet50함수를 실행\n",
    "6. resnet50함수에서 parameter(output_layers, pretrained)를 고려해서 모델 생성 후 반환 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- run_training.py\n",
    "- train_settings/transt/transt.py (run)\n",
    "- models/tracking/transt.py (transt_resnet50)\n",
    "- models/backbone/transt_backbone.py (build_backbone, Backbone Class<BacknboneBase 상속>)\n",
    "- models/backbone/resnet.py (resnet50) \n",
    "- 모든 경로는 TransT/ltr 디렉토리에 위치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ltr.admin.settings as ws_settings\n",
    "import ltr.models.tracking.transt as transt_models\n",
    "import ltr.models.backbone as backbones\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "백본 네트워크 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models/backbone/transt_backbone.py (build_backbone-Backbone, line:80)\n",
    "output_layers=['layer3']\n",
    "pretrained=True\n",
    "frozen_layers=()\n",
    "backbone = backbones.resnet50(output_layers=output_layers, pretrained=pretrained,\n",
    "                                      frozen_layers=frozen_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50 (수정본)\n",
    "- 마지막 스테이지(layer4) 제거 \n",
    "- layer3의 downsampling unit에서 stride를 2에서 1로 변경 -> feature resolution을 증가\n",
    "- layer3의 Conv2D를 Dilation Convolution(stride:2)로 변경 -> Receptive Field를 증가\n",
    "- 최종 output: 1024 x W/8 x H/8 [type:collections.OrderedDict]\n",
    "\n",
    "collections.OrderedDict: [output_layer_name, tensor]로 구성된 자료구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "      Layer (type)            Input Shape         Param #     Tr. Param #\n",
      "==========================================================================\n",
      "          Conv2d-1      [38, 3, 256, 256]           9,408           9,408\n",
      "     BatchNorm2d-2     [38, 64, 128, 128]             128             128\n",
      "            ReLU-3     [38, 64, 128, 128]               0               0\n",
      "       MaxPool2d-4     [38, 64, 128, 128]               0               0\n",
      "      Bottleneck-5       [38, 64, 64, 64]          75,008          75,008\n",
      "      Bottleneck-6      [38, 256, 64, 64]          70,400          70,400\n",
      "      Bottleneck-7      [38, 256, 64, 64]          70,400          70,400\n",
      "      Bottleneck-8      [38, 256, 64, 64]         379,392         379,392\n",
      "      Bottleneck-9      [38, 512, 32, 32]         280,064         280,064\n",
      "     Bottleneck-10      [38, 512, 32, 32]         280,064         280,064\n",
      "     Bottleneck-11      [38, 512, 32, 32]         280,064         280,064\n",
      "     Bottleneck-12      [38, 512, 32, 32]       1,512,448       1,512,448\n",
      "     Bottleneck-13     [38, 1024, 32, 32]       1,117,184       1,117,184\n",
      "     Bottleneck-14     [38, 1024, 32, 32]       1,117,184       1,117,184\n",
      "     Bottleneck-15     [38, 1024, 32, 32]       1,117,184       1,117,184\n",
      "     Bottleneck-16     [38, 1024, 32, 32]       1,117,184       1,117,184\n",
      "     Bottleneck-17     [38, 1024, 32, 32]       1,117,184       1,117,184\n",
      "==========================================================================\n",
      "Total params: 8,543,296\n",
      "Trainable params: 8,543,296\n",
      "Non-trainable params: 0\n",
      "--------------------------------------------------------------------------\n",
      "<bound method Module.parameters of ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      ")>\n",
      "<class 'collections.OrderedDict'>\n"
     ]
    }
   ],
   "source": [
    "# Input: SearchRegion (256x256x3), batch_size:38\n",
    "# Output: SearchFeature (32x32x1024)\n",
    "input=torch.zeros(38, 3, 256, 256)\n",
    "print(pytorch_model_summary.summary(backbone, input, show_input=True))\n",
    "print(backbone.parameters)\n",
    "print(type(backbone(input)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EfficientNet B4\n",
    "- Final linear layer 제거 (AdaptiveAvgPool2d,Dropout,Linear) -> Feature Extractor만 남김\n",
    "- 수정된 EfficientNet에 bilinear interpolation을 추가함 (efficientnet의 input_resolution 일치, 기존 backbone과 output_resolution 일치) \n",
    "- BottleNeck Layer는 선택사항 \n",
    "- 최종 output: 1024 x W/8 x H/8 [type:torch.Tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ltr.admin.settings as ws_settings\n",
    "import ltr.models.tracking.transt as transt_models\n",
    "import ltr.models.backbone as backbones\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_model_summary\n",
    "import math\n",
    "from efficientnet_pytorch_edit import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEfficientNet(nn.Module):\n",
    "    def __init__(self,efficientnet,eff_in_size=380,eff_out_chnl=1792):\n",
    "        super().__init__()\n",
    "\n",
    "        # EfficientNet Input Size (default:380x380)\n",
    "        self.EffInSize=eff_in_size\n",
    "        # EfficientNet Output Size (default:12x12)\n",
    "        self.EffOutSize=math.ceil(eff_in_size/32)\n",
    "\n",
    "        # Search Region Size\n",
    "        self.SearchImageSize=256\n",
    "        self.SearchFeatureSize=32\n",
    "        # Template Size\n",
    "        self.TemplateImageSize=128\n",
    "        self.TemplateFeatureSize=16\n",
    "        \n",
    "        # upsampling for identical resolution\n",
    "        self.upsampleSin=nn.Upsample(scale_factor=(self.EffInSize/self.SearchImageSize), mode='bilinear', align_corners=False) \n",
    "        self.upsampleSout=nn.Upsample(scale_factor=(self.SearchFeatureSize/self.EffOutSize), mode='bilinear', align_corners=False) \n",
    "        self.upsampleTin=nn.Upsample(scale_factor=(self.EffInSize/self.TemplateImageSize), mode='bilinear', align_corners=False) \n",
    "        self.upsampleTout=nn.Upsample(scale_factor=(self.TemplateFeatureSize/self.EffOutSize), mode='bilinear', align_corners=False) \n",
    "\n",
    "        # EfficientNet Feature Extractor\n",
    "        self.effConv = efficientnet\n",
    "\n",
    "        # output channel number is identical with resnet50 \n",
    "        self.stage1=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=eff_out_chnl,out_channels=1024,kernel_size=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # BottleNeck\n",
    "        self.stage2=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1024,out_channels=512,kernel_size=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512,out_channels=1024,kernel_size=1),\n",
    "            nn.BatchNorm2d(1024)\n",
    "        )\n",
    "        self.relu=nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        # tensor x_width size \n",
    "        y=x.size(dim=3) \n",
    "\n",
    "        # Search Region\n",
    "        if y == self.SearchImageSize:\n",
    "            x=self.upsampleSin(x) # (256x256) -> (380x380)\n",
    "            x = self.effConv(x) # (380x380) -> (12x12)\n",
    "            x=self.upsampleSout(x) # (12x12) -> (32x32)\n",
    "        # Template\n",
    "        elif y==self.TemplateImageSize:\n",
    "            x=self.upsampleTin(x) # (256x256) -> (380x380)\n",
    "            x = self.effConv(x) # (380x380) -> (12x12)\n",
    "            x=self.upsampleTout(x) # (12x12) -> (16x16)\n",
    "            \n",
    "        # output channel number is identical with resnet50 \n",
    "        # (32x32x1792) -> (32x32x1024), (16x16x1792) -> (16x16x1024)\n",
    "        x=self.stage1(x)\n",
    "        \n",
    "        # BottleNeck with Residual Connection \n",
    "        fx=self.stage2(x) # F(x) \n",
    "        x=fx+x  # F(x)+x\n",
    "        x=self.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEfficientNet2(nn.Module):\n",
    "    def __init__(self,efficientnet):\n",
    "        super().__init__()\n",
    "        # EfficientNet Feature Extractor\n",
    "        self.effConv = efficientnet\n",
    "\n",
    "        # output channel number is identical with resnet50 \n",
    "        self.stage=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=80,out_channels=160,kernel_size=1),\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=160,out_channels=320,kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(320),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=320,out_channels=640,kernel_size=1),\n",
    "            nn.BatchNorm2d(640),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=640,out_channels=1024,kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.effConv(x)\n",
    "        x=self.stage(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_model(model):\n",
    "    # MBConv, BatchNorm -> freeze\n",
    "    for ct, child in enumerate(model.children()):\n",
    "        print(type(child))\n",
    "        if isinstance(child,nn.modules.batchnorm.BatchNorm2d):\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "        elif isinstance(child,nn.modules.container.Sequential):\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n",
      "<class 'efficientnet_pytorch_edit.utils.Conv2dStaticSamePadding'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'torch.nn.modules.linear.Identity'>\n",
      "<class 'torch.nn.modules.linear.Identity'>\n",
      "<class 'efficientnet_pytorch_edit.utils.MemoryEfficientSwish'>\n",
      "-------------------------------------------------------------------------\n",
      "      Layer (type)           Input Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "    EfficientNet-1      [1, 3, 256, 256]         982,268           1,728\n",
      "          Conv2d-2       [1, 80, 32, 32]          12,960          12,960\n",
      "     BatchNorm2d-3      [1, 160, 32, 32]             320             320\n",
      "            ReLU-4      [1, 160, 32, 32]               0               0\n",
      "          Conv2d-5      [1, 160, 32, 32]         461,120         461,120\n",
      "     BatchNorm2d-6      [1, 320, 32, 32]             640             640\n",
      "            ReLU-7      [1, 320, 32, 32]               0               0\n",
      "          Conv2d-8      [1, 320, 32, 32]         205,440         205,440\n",
      "     BatchNorm2d-9      [1, 640, 32, 32]           1,280           1,280\n",
      "           ReLU-10      [1, 640, 32, 32]               0               0\n",
      "         Conv2d-11      [1, 640, 32, 32]       5,899,264       5,899,264\n",
      "    BatchNorm2d-12     [1, 1024, 32, 32]           2,048           2,048\n",
      "           ReLU-13     [1, 1024, 32, 32]               0               0\n",
      "=========================================================================\n",
      "Total params: 7,565,340\n",
      "Trainable params: 6,584,800\n",
      "Non-trainable params: 980,540\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# EfficientNet B2 -> eff_in_size=260, eff_out_chnl=1408\n",
    "# EfficientNet B3 -> eff_in_size=300, eff_out_chnl=1536\n",
    "# EfficientNet B4 -> eff_in_size=380, eff_out_chnl=1792 [default]\n",
    "model=EfficientNet.from_pretrained('efficientnet-b7')\n",
    "model._blocks=nn.Sequential(*list(model._blocks.children())[:-37])\n",
    "model._conv_head=nn.Identity()\n",
    "model._bn1=nn.Identity()\n",
    "model=freeze_model(model)\n",
    "myefficientnet=MyEfficientNet2(model)\n",
    "print(pytorch_model_summary.summary(myefficientnet, input, show_input=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n",
      "------------------------------------------------------------------------------------\n",
      "                 Layer (type)           Input Shape         Param #     Tr. Param #\n",
      "====================================================================================\n",
      "    Conv2dStaticSamePadding-1      [1, 3, 256, 256]           1,728           1,728\n",
      "                BatchNorm2d-2     [1, 64, 128, 128]             128             128\n",
      "       MemoryEfficientSwish-3     [1, 64, 128, 128]               0               0\n",
      "                MBConvBlock-4     [1, 64, 128, 128]           4,944           4,944\n",
      "                MBConvBlock-5     [1, 32, 128, 128]           1,992           1,992\n",
      "                MBConvBlock-6     [1, 32, 128, 128]           1,992           1,992\n",
      "                MBConvBlock-7     [1, 32, 128, 128]           1,992           1,992\n",
      "                MBConvBlock-8     [1, 32, 128, 128]          21,224          21,224\n",
      "                MBConvBlock-9       [1, 48, 64, 64]          38,700          38,700\n",
      "               MBConvBlock-10       [1, 48, 64, 64]          38,700          38,700\n",
      "               MBConvBlock-11       [1, 48, 64, 64]          38,700          38,700\n",
      "               MBConvBlock-12       [1, 48, 64, 64]          38,700          38,700\n",
      "               MBConvBlock-13       [1, 48, 64, 64]          38,700          38,700\n",
      "               MBConvBlock-14       [1, 48, 64, 64]          38,700          38,700\n",
      "               MBConvBlock-15       [1, 48, 64, 64]          52,588          52,588\n",
      "               MBConvBlock-16       [1, 80, 32, 32]         110,580         110,580\n",
      "               MBConvBlock-17       [1, 80, 32, 32]         110,580         110,580\n",
      "               MBConvBlock-18       [1, 80, 32, 32]         110,580         110,580\n",
      "               MBConvBlock-19       [1, 80, 32, 32]         110,580         110,580\n",
      "               MBConvBlock-20       [1, 80, 32, 32]         110,580         110,580\n",
      "               MBConvBlock-21       [1, 80, 32, 32]         110,580         110,580\n",
      "               MBConvBlock-22       [1, 80, 32, 32]         141,460         141,460\n",
      "               MBConvBlock-23      [1, 160, 16, 16]         397,800         397,800\n",
      "               MBConvBlock-24      [1, 160, 16, 16]         397,800         397,800\n",
      "               MBConvBlock-25      [1, 160, 16, 16]         397,800         397,800\n",
      "               MBConvBlock-26      [1, 160, 16, 16]         397,800         397,800\n",
      "               MBConvBlock-27      [1, 160, 16, 16]         397,800         397,800\n",
      "               MBConvBlock-28      [1, 160, 16, 16]         397,800         397,800\n",
      "               MBConvBlock-29      [1, 160, 16, 16]         397,800         397,800\n",
      "               MBConvBlock-30      [1, 160, 16, 16]         397,800         397,800\n",
      "               MBConvBlock-31      [1, 160, 16, 16]         397,800         397,800\n",
      "               MBConvBlock-32      [1, 160, 16, 16]         474,728         474,728\n",
      "               MBConvBlock-33      [1, 224, 16, 16]         793,464         793,464\n",
      "               MBConvBlock-34      [1, 224, 16, 16]         793,464         793,464\n",
      "               MBConvBlock-35      [1, 224, 16, 16]         793,464         793,464\n",
      "               MBConvBlock-36      [1, 224, 16, 16]         793,464         793,464\n",
      "               MBConvBlock-37      [1, 224, 16, 16]         793,464         793,464\n",
      "               MBConvBlock-38      [1, 224, 16, 16]         793,464         793,464\n",
      "               MBConvBlock-39      [1, 224, 16, 16]         793,464         793,464\n",
      "               MBConvBlock-40      [1, 224, 16, 16]         793,464         793,464\n",
      "               MBConvBlock-41      [1, 224, 16, 16]         793,464         793,464\n",
      "               MBConvBlock-42      [1, 224, 16, 16]       1,008,824       1,008,824\n",
      "               MBConvBlock-43        [1, 384, 8, 8]       2,281,824       2,281,824\n",
      "               MBConvBlock-44        [1, 384, 8, 8]       2,281,824       2,281,824\n",
      "               MBConvBlock-45        [1, 384, 8, 8]       2,281,824       2,281,824\n",
      "               MBConvBlock-46        [1, 384, 8, 8]       2,281,824       2,281,824\n",
      "               MBConvBlock-47        [1, 384, 8, 8]       2,281,824       2,281,824\n",
      "               MBConvBlock-48        [1, 384, 8, 8]       2,281,824       2,281,824\n",
      "               MBConvBlock-49        [1, 384, 8, 8]       2,281,824       2,281,824\n",
      "               MBConvBlock-50        [1, 384, 8, 8]       2,281,824       2,281,824\n",
      "               MBConvBlock-51        [1, 384, 8, 8]       2,281,824       2,281,824\n",
      "               MBConvBlock-52        [1, 384, 8, 8]       2,281,824       2,281,824\n",
      "               MBConvBlock-53        [1, 384, 8, 8]       2,281,824       2,281,824\n",
      "               MBConvBlock-54        [1, 384, 8, 8]       2,281,824       2,281,824\n",
      "               MBConvBlock-55        [1, 384, 8, 8]       2,835,296       2,835,296\n",
      "               MBConvBlock-56        [1, 640, 8, 8]       6,199,200       6,199,200\n",
      "               MBConvBlock-57        [1, 640, 8, 8]       6,199,200       6,199,200\n",
      "               MBConvBlock-58        [1, 640, 8, 8]       6,199,200       6,199,200\n",
      "   Conv2dStaticSamePadding-59        [1, 640, 8, 8]       1,638,400       1,638,400\n",
      "               BatchNorm2d-60       [1, 2560, 8, 8]           5,120           5,120\n",
      "====================================================================================\n",
      "Total params: 63,786,960\n",
      "Trainable params: 63,786,960\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------\n",
      "      Layer (type)           Input Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "    EfficientNet-1      [1, 3, 256, 256]         982,268         982,140\n",
      "          Conv2d-2       [1, 80, 32, 32]          12,960          12,960\n",
      "     BatchNorm2d-3      [1, 160, 32, 32]             320             320\n",
      "            ReLU-4      [1, 160, 32, 32]               0               0\n",
      "          Conv2d-5      [1, 160, 32, 32]         461,120         461,120\n",
      "     BatchNorm2d-6      [1, 320, 32, 32]             640             640\n",
      "            ReLU-7      [1, 320, 32, 32]               0               0\n",
      "          Conv2d-8      [1, 320, 32, 32]         205,440         205,440\n",
      "     BatchNorm2d-9      [1, 640, 32, 32]           1,280           1,280\n",
      "           ReLU-10      [1, 640, 32, 32]               0               0\n",
      "         Conv2d-11      [1, 640, 32, 32]       5,899,264       5,899,264\n",
      "    BatchNorm2d-12     [1, 1024, 32, 32]           2,048           2,048\n",
      "           ReLU-13     [1, 1024, 32, 32]               0               0\n",
      "=========================================================================\n",
      "Total params: 7,565,340\n",
      "Trainable params: 7,565,212\n",
      "Non-trainable params: 128\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Input: SearchRegion (256x256x3), batch_size:38\n",
    "# Output: SearchFeature (32x32x1024)\n",
    "input=torch.zeros(1, 3, 256, 256)\n",
    "print(pytorch_model_summary.summary(EfficientNet.from_pretrained('efficientnet-b7'), input, show_input=True))\n",
    "print(pytorch_model_summary.summary(myefficientnet, input, show_input=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TransT의 변경된 Feature Extractor 실행 구조\n",
    "\n",
    "1. run_training.py에서 settings 객체 생성, train_settings/transt/transt.py경로의 run함수 실행\n",
    "2. run 함수에서 settings 객체의 필드를 초기화, models/tracking/transt.py 경로의 transt_effnet함수를 실행 \n",
    "3. transt_effnet함수에서 backbone을 불러오기 위해 models/backbone/transt_backbone.py 경로의 build_backbone함수를 실행\n",
    "4. build_backbone함수에서 backbone을 정의하기 위해 MyBackbone 클래스 생성자를 호출 (인스턴스화)\n",
    "5. Backbone 생성자에서 backbone을 생성하기 위해 models/backbone/efficientnet.py 경로의 effnet함수를 실행\n",
    "5. effnet함수에서 모델 생성 후 반환 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- run_training.py\n",
    "- train_settings/transt/transt.py (run)\n",
    "- models/tracking/transt.py (transt_effnet)\n",
    "- models/backbone/transt_backbone.py (build_backbone, Backbone Class<MyBacknboneBase 상속>)\n",
    "- models/backbone/efficientnet.py (effnet) \n",
    "- 모든 경로는 TransT/ltr 디렉토리에 위치\n",
    "\n",
    "P.s. MyEfficientNet의 출력 타입과 기존 네트워크의 출력 타입이 다르므로 BackboneBase 클래스를 수정해서 MyBackboneBase 클래스를 제작함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('transt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78ad38291b288c6d101dbb825e4bf6ad9648dc83f270306dab6eec56a5d92a4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
