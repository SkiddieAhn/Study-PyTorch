{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_model_summary\n",
    "from model_resnet import *\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torchvision.models.resnet import model_urls\n",
    "from cbam import *\n",
    "import torchvision_edit.models_e as models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=torch.device('cuda'if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform=transforms.Compose([transforms.ToTensor(),\n",
    "transforms.RandomHorizontalFlip(),\n",
    "transforms.RandomVerticalFlip(),\n",
    "transforms.Normalize((0.5,),(0.5,))])\n",
    "\n",
    "test_transform=transforms.Compose([transforms.ToTensor(),\n",
    "transforms.Normalize((0.5,),(0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahnsunghyun/.local/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "trainset=datasets.FashionMNIST(root='content',\n",
    "train=True,download=True,\n",
    "transform=train_transform)\n",
    "\n",
    "testset=datasets.FashionMNIST(root='content',\n",
    "train=False,download=True,\n",
    "transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(trainset))\n",
    "print(len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(trainset,batch_size=128,shuffle=True,num_workers=6)\n",
    "test_loader=DataLoader(testset,batch_size=128,shuffle=False,num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 1, 28, 28]), torch.Size([128]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images,labels=next(iter(train_loader))\n",
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch=len(train_loader)\n",
    "print(steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x864 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = ('T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "figure=plt.figure(figsize=(12,12))\n",
    "cols,rows=4,4\n",
    "for i in range(1,cols*rows+1):\n",
    "    image=images[i].squeeze()\n",
    "    label_idx=labels[i].item()\n",
    "    label=classes[label_idx]\n",
    "\n",
    "    figure.add_subplot(rows,cols,i)\n",
    "    plt.title(label)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image,cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm2d(nn.LayerNorm):\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # pytorch version >= 0.9.0\n",
    "        # x = x.permute(0, 2, 3, 1)\n",
    "        # x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
    "        # x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        # pytorch version < 0.9.0\n",
    "        x = x.transpose(1,2)\n",
    "        x = x.transpose(2,3)\n",
    "        x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
    "        x = x.transpose(2,3)\n",
    "        x = x.transpose(1,2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.convnext_tiny(weights=models.ConvNeXt_Tiny_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# 모델 일부만 사용 \n",
    "model.features=nn.Sequential(*list(model.features.children())[0:6])\n",
    "model.avgpool=nn.Identity()\n",
    "model.classifier=nn.Identity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습된 weight 일부 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=model_zoo.load_url(model_urls['resnet50'])\n",
    "\n",
    "def remove(key):\n",
    "    del d[key]\n",
    "    return d\n",
    "\n",
    "remove_list=['layer4.0.conv1.weight', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.conv2.weight', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.conv3.weight', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.1.conv1.weight', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.conv2.weight', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.conv3.weight', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.2.conv1.weight', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.conv2.weight', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.conv3.weight', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'fc.weight', 'fc.bias']\n",
    "\n",
    "for i in range(len(remove_list)):\n",
    "    remove(remove_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습된 모델 생성 코드 (실험에서는 적용 x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahnsunghyun/pytorch/ResNet/model_resnet.py:134: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(self.state_dict()[key], mode='fan_out')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 정의 (수정된 ResNet50)\n",
    "model = ResidualNet(\"ImageNet\",50,1000,None)\n",
    "\n",
    "# 학습된 weight 불러오기\n",
    "# model.load_state_dict(d, strict=False)\n",
    "\n",
    "# GPU 환경에서 연산\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "      Layer (type)           Input Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1      [128, 3, 28, 28]           9,408           9,408\n",
      "     BatchNorm2d-2     [128, 64, 14, 14]             128             128\n",
      "            ReLU-3     [128, 64, 14, 14]               0               0\n",
      "       MaxPool2d-4     [128, 64, 14, 14]               0               0\n",
      "      Bottleneck-5       [128, 64, 7, 7]          75,008          75,008\n",
      "      Bottleneck-6      [128, 256, 7, 7]          70,400          70,400\n",
      "      Bottleneck-7      [128, 256, 7, 7]          70,400          70,400\n",
      "      Bottleneck-8      [128, 256, 7, 7]         379,392         379,392\n",
      "      Bottleneck-9      [128, 512, 4, 4]         280,064         280,064\n",
      "     Bottleneck-10      [128, 512, 4, 4]         280,064         280,064\n",
      "     Bottleneck-11      [128, 512, 4, 4]         280,064         280,064\n",
      "     Bottleneck-12      [128, 512, 4, 4]       1,512,448       1,512,448\n",
      "     Bottleneck-13     [128, 1024, 4, 4]       1,117,184       1,117,184\n",
      "     Bottleneck-14     [128, 1024, 4, 4]       1,117,184       1,117,184\n",
      "     Bottleneck-15     [128, 1024, 4, 4]       1,117,184       1,117,184\n",
      "     Bottleneck-16     [128, 1024, 4, 4]       1,117,184       1,117,184\n",
      "     Bottleneck-17     [128, 1024, 4, 4]       1,117,184       1,117,184\n",
      "=========================================================================\n",
      "Total params: 8,543,296\n",
      "Trainable params: 8,543,296\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n",
      "<bound method Module.parameters of ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      ")>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "input=torch.zeros(128, 3, 28, 28).to(device)\n",
    "print(pytorch_model_summary.summary(model, input, show_input=True))\n",
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나의 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet,self).__init__()\n",
    "        self.upsample=nn.Upsample(scale_factor=2, mode='bicubic', align_corners=False)\n",
    "        self.conv=nn.Conv2d(1,3,3)\n",
    "        self.batchN=nn.BatchNorm2d(3)\n",
    "        self.network=model\n",
    "        self.layernorm=LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
    "        self.cbam = CBAM(384, 16) # CBAM\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(384, 384),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(384, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.upsample(x)\n",
    "        x=F.relu(self.conv(x))\n",
    "        x=self.batchN(x)\n",
    "        x=self.network(x)\n",
    "        x=self.cbam(x)\n",
    "        x=self.max_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x=self.fc_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyNet(\n",
       "  (upsample): Upsample(scale_factor=2.0, mode=bicubic)\n",
       "  (conv): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (batchN): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (network): ConvNeXt(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "        (1): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (4): GELU()\n",
       "            (5): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "        )\n",
       "        (1): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (4): GELU()\n",
       "            (5): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0058823529411764705, mode=row)\n",
       "        )\n",
       "        (2): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (4): GELU()\n",
       "            (5): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.011764705882352941, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (4): GELU()\n",
       "            (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.017647058823529415, mode=row)\n",
       "        )\n",
       "        (1): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (4): GELU()\n",
       "            (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.023529411764705882, mode=row)\n",
       "        )\n",
       "        (2): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (4): GELU()\n",
       "            (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.029411764705882353, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (4): GELU()\n",
       "            (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.03529411764705883, mode=row)\n",
       "        )\n",
       "        (1): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (4): GELU()\n",
       "            (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0411764705882353, mode=row)\n",
       "        )\n",
       "        (2): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (4): GELU()\n",
       "            (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.047058823529411764, mode=row)\n",
       "        )\n",
       "        (3): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (4): GELU()\n",
       "            (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.052941176470588235, mode=row)\n",
       "        )\n",
       "        (4): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (4): GELU()\n",
       "            (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.058823529411764705, mode=row)\n",
       "        )\n",
       "        (5): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (4): GELU()\n",
       "            (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.06470588235294118, mode=row)\n",
       "        )\n",
       "        (6): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (4): GELU()\n",
       "            (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.07058823529411766, mode=row)\n",
       "        )\n",
       "        (7): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (4): GELU()\n",
       "            (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.07647058823529412, mode=row)\n",
       "        )\n",
       "        (8): CNBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (1): Permute()\n",
       "            (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "            (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (4): GELU()\n",
       "            (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (6): Permute()\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0823529411764706, mode=row)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (avgpool): Identity()\n",
       "    (classifier): Identity()\n",
       "  )\n",
       "  (layernorm): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
       "  (cbam): CBAM(\n",
       "    (ChannelGate): ChannelGate(\n",
       "      (mlp): Sequential(\n",
       "        (0): Flatten()\n",
       "        (1): Linear(in_features=384, out_features=24, bias=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=24, out_features=384, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (SpatialGate): SpatialGate(\n",
       "      (compress): ChannelPool()\n",
       "      (spatial): BasicConv(\n",
       "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc_layer): Sequential(\n",
       "    (0): Dropout(p=0.1, inplace=False)\n",
       "    (1): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Linear(in_features=384, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynet=MyNet()\n",
    "mynet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나의 모델 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "      Layer (type)         Input Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "        Upsample-1      [1, 1, 28, 28]               0               0\n",
      "          Conv2d-2      [1, 1, 56, 56]              30              30\n",
      "     BatchNorm2d-3      [1, 3, 54, 54]               6               6\n",
      "        ConvNeXt-4      [1, 3, 54, 54]      12,348,000      12,348,000\n",
      "            CBAM-5      [1, 384, 3, 3]          18,940          18,940\n",
      "       MaxPool2d-6      [1, 384, 3, 3]               0               0\n",
      "         Dropout-7            [1, 384]               0               0\n",
      "          Linear-8            [1, 384]         147,840         147,840\n",
      "            ReLU-9            [1, 384]               0               0\n",
      "        Dropout-10            [1, 384]               0               0\n",
      "         Linear-11            [1, 384]           3,850           3,850\n",
      "=======================================================================\n",
      "Total params: 12,518,666\n",
      "Trainable params: 12,518,666\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahnsunghyun/.local/lib/python3.8/site-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "input=torch.zeros(1,1,28,28).to(device)\n",
    "print(pytorch_model_summary.summary(mynet, input, show_input=True))\n",
    "print(type(mynet(input)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손실함수와 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(mynet.parameters(), lr=0.0001, eps=1e-08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iter: 100, Loss:0.24457577341146816\n",
      "Epoch: 1, Iter: 200, Loss:0.09615004431210093\n",
      "Epoch: 1, Iter: 300, Loss:0.08045083824505429\n",
      "Epoch: 1, Iter: 400, Loss:0.06712215563762924\n",
      "Epoch: 1, Acc:82.36773720682302\n",
      "Epoch: 2, Iter: 100, Loss:0.055834867139614976\n",
      "Epoch: 2, Iter: 200, Loss:0.05312608198316367\n",
      "Epoch: 2, Iter: 300, Loss:0.05147835543986831\n",
      "Epoch: 2, Iter: 400, Loss:0.049015825983684966\n",
      "Epoch: 2, Acc:91.46788379530916\n",
      "Epoch: 3, Iter: 100, Loss:0.04400282786853278\n",
      "Epoch: 3, Iter: 200, Loss:0.04441433185453354\n",
      "Epoch: 3, Iter: 300, Loss:0.042933810510233775\n",
      "Epoch: 3, Iter: 400, Loss:0.04294714430120708\n",
      "Epoch: 3, Acc:92.90045309168444\n",
      "Epoch: 4, Iter: 100, Loss:0.03783759015646062\n",
      "Epoch: 4, Iter: 200, Loss:0.03712905317481393\n",
      "Epoch: 4, Iter: 300, Loss:0.038921091268692955\n",
      "Epoch: 4, Iter: 400, Loss:0.03569190880891357\n",
      "Epoch: 4, Acc:93.84661513859275\n",
      "Epoch: 5, Iter: 100, Loss:0.03337748329649602\n",
      "Epoch: 5, Iter: 200, Loss:0.03449981407061823\n",
      "Epoch: 5, Iter: 300, Loss:0.03258160436585514\n",
      "Epoch: 5, Iter: 400, Loss:0.03315712433697572\n",
      "Epoch: 5, Acc:94.40964818763327\n",
      "Epoch: 6, Iter: 100, Loss:0.029205092044273163\n",
      "Epoch: 6, Iter: 200, Loss:0.030423655986849433\n",
      "Epoch: 6, Iter: 300, Loss:0.029994749223817386\n",
      "Epoch: 6, Iter: 400, Loss:0.029572748354693718\n",
      "Epoch: 6, Acc:95.01265991471216\n",
      "Epoch: 7, Iter: 100, Loss:0.026187654330468636\n",
      "Epoch: 7, Iter: 200, Loss:0.027582601459422852\n",
      "Epoch: 7, Iter: 300, Loss:0.025448778568745167\n",
      "Epoch: 7, Iter: 400, Loss:0.026809056585372637\n",
      "Epoch: 7, Acc:95.64898720682302\n",
      "Epoch: 8, Iter: 100, Loss:0.024294658851966675\n",
      "Epoch: 8, Iter: 200, Loss:0.025754261515669223\n",
      "Epoch: 8, Iter: 300, Loss:0.022912602267984642\n",
      "Epoch: 8, Iter: 400, Loss:0.024697015113604347\n",
      "Epoch: 8, Acc:96.02545309168444\n",
      "Epoch: 9, Iter: 100, Loss:0.021134155041881715\n",
      "Epoch: 9, Iter: 200, Loss:0.020741327862336692\n",
      "Epoch: 9, Iter: 300, Loss:0.022302940662608725\n",
      "Epoch: 9, Iter: 400, Loss:0.02408916730362215\n",
      "Epoch: 9, Acc:96.37859808102345\n",
      "Epoch: 10, Iter: 100, Loss:0.01917757697578178\n",
      "Epoch: 10, Iter: 200, Loss:0.019128666066729437\n",
      "Epoch: 10, Iter: 300, Loss:0.01940634818092338\n",
      "Epoch: 10, Iter: 400, Loss:0.02028810436219803\n",
      "Epoch: 10, Acc:96.76839019189765\n",
      "Epoch: 11, Iter: 100, Loss:0.01750019149405997\n",
      "Epoch: 11, Iter: 200, Loss:0.01868605090658675\n",
      "Epoch: 11, Iter: 300, Loss:0.018602446051262843\n",
      "Epoch: 11, Iter: 400, Loss:0.018523025888401563\n",
      "Epoch: 11, Acc:96.98160980810235\n",
      "Epoch: 12, Iter: 100, Loss:0.01677967970575224\n",
      "Epoch: 12, Iter: 200, Loss:0.015467553536520838\n",
      "Epoch: 12, Iter: 300, Loss:0.015955707951903597\n",
      "Epoch: 12, Iter: 400, Loss:0.017300995162078565\n",
      "Epoch: 12, Acc:97.38139658848614\n",
      "Epoch: 13, Iter: 100, Loss:0.013903995491325982\n",
      "Epoch: 13, Iter: 200, Loss:0.016082354731905436\n",
      "Epoch: 13, Iter: 300, Loss:0.01517336097543936\n",
      "Epoch: 13, Iter: 400, Loss:0.01548986899843221\n",
      "Epoch: 13, Acc:97.50632995735607\n",
      "Epoch: 14, Iter: 100, Loss:0.013135960256097033\n",
      "Epoch: 14, Iter: 200, Loss:0.014185517827775686\n",
      "Epoch: 14, Iter: 300, Loss:0.012836848965474665\n",
      "Epoch: 14, Iter: 400, Loss:0.014435906255089524\n",
      "Epoch: 14, Acc:97.77118869936034\n",
      "Epoch: 15, Iter: 100, Loss:0.01187123797103159\n",
      "Epoch: 15, Iter: 200, Loss:0.011084425569907116\n",
      "Epoch: 15, Iter: 300, Loss:0.012550666655248989\n",
      "Epoch: 15, Iter: 400, Loss:0.013283553394252684\n",
      "Epoch: 15, Acc:98.03105010660981\n",
      "Epoch: 16, Iter: 100, Loss:0.01166373366184199\n",
      "Epoch: 16, Iter: 200, Loss:0.010605898620223186\n",
      "Epoch: 16, Iter: 300, Loss:0.012498613117314351\n",
      "Epoch: 16, Iter: 400, Loss:0.012452323914074631\n",
      "Epoch: 16, Acc:98.0493736673774\n",
      "Epoch: 17, Iter: 100, Loss:0.010757449777054189\n",
      "Epoch: 17, Iter: 200, Loss:0.010276991608880286\n",
      "Epoch: 17, Iter: 300, Loss:0.010184704867213457\n",
      "Epoch: 17, Iter: 400, Loss:0.011747949971144261\n",
      "Epoch: 17, Acc:98.2309434968017\n",
      "Epoch: 18, Iter: 100, Loss:0.010726862078679523\n",
      "Epoch: 18, Iter: 200, Loss:0.008972445428411144\n",
      "Epoch: 18, Iter: 300, Loss:0.010420765738680102\n",
      "Epoch: 18, Iter: 400, Loss:0.00865608710410403\n",
      "Epoch: 18, Acc:98.40085287846482\n",
      "Epoch: 19, Iter: 100, Loss:0.009347820917624972\n",
      "Epoch: 19, Iter: 200, Loss:0.009239777229599226\n",
      "Epoch: 19, Iter: 300, Loss:0.009317145928113\n",
      "Epoch: 19, Iter: 400, Loss:0.01000254298411389\n",
      "Epoch: 19, Acc:98.40585021321962\n",
      "Epoch: 20, Iter: 100, Loss:0.0087141916215388\n",
      "Epoch: 20, Iter: 200, Loss:0.00876463380560819\n",
      "Epoch: 20, Iter: 300, Loss:0.009053607074631207\n",
      "Epoch: 20, Iter: 400, Loss:0.008966659494578394\n",
      "Epoch: 20, Acc:98.55410447761194\n",
      "Epoch: 21, Iter: 100, Loss:0.007877017590286793\n",
      "Epoch: 21, Iter: 200, Loss:0.008751339937891883\n",
      "Epoch: 21, Iter: 300, Loss:0.008460868537219475\n",
      "Epoch: 21, Iter: 400, Loss:0.008555549745962246\n",
      "Epoch: 21, Acc:98.56576492537313\n",
      "Epoch: 22, Iter: 100, Loss:0.008090783390147028\n",
      "Epoch: 22, Iter: 200, Loss:0.007436933115557599\n",
      "Epoch: 22, Iter: 300, Loss:0.007336727762495531\n",
      "Epoch: 22, Iter: 400, Loss:0.007956702280531464\n",
      "Epoch: 22, Acc:98.67404051172709\n",
      "Epoch: 23, Iter: 100, Loss:0.006489409994619932\n",
      "Epoch: 23, Iter: 200, Loss:0.007023333356396031\n",
      "Epoch: 23, Iter: 300, Loss:0.007793372786883861\n",
      "Epoch: 23, Iter: 400, Loss:0.007200395327998694\n",
      "Epoch: 23, Acc:98.807302771855\n",
      "Epoch: 24, Iter: 100, Loss:0.0060995807146419214\n",
      "Epoch: 24, Iter: 200, Loss:0.006802315435020813\n",
      "Epoch: 24, Iter: 300, Loss:0.006518632215735659\n",
      "Epoch: 24, Iter: 400, Loss:0.007777437178501443\n",
      "Epoch: 24, Acc:98.823960554371\n",
      "Epoch: 25, Iter: 100, Loss:0.006625947103635081\n",
      "Epoch: 25, Iter: 200, Loss:0.006825789418528233\n",
      "Epoch: 25, Iter: 300, Loss:0.006556272407425746\n",
      "Epoch: 25, Iter: 400, Loss:0.006941707011238773\n",
      "Epoch: 25, Acc:98.84061833688699\n",
      "Epoch: 26, Iter: 100, Loss:0.00597646354294535\n",
      "Epoch: 26, Iter: 200, Loss:0.006348489946536799\n",
      "Epoch: 26, Iter: 300, Loss:0.007400948153649852\n",
      "Epoch: 26, Iter: 400, Loss:0.006405328009237867\n",
      "Epoch: 26, Acc:98.88392857142857\n",
      "Epoch: 27, Iter: 100, Loss:0.005978728414201406\n",
      "Epoch: 27, Iter: 200, Loss:0.0066175154908729005\n",
      "Epoch: 27, Iter: 300, Loss:0.0060518873405696425\n",
      "Epoch: 27, Iter: 400, Loss:0.005226003479208551\n",
      "Epoch: 27, Acc:98.97721215351812\n",
      "Epoch: 28, Iter: 100, Loss:0.0050975629853319\n",
      "Epoch: 28, Iter: 200, Loss:0.005932059864561234\n",
      "Epoch: 28, Iter: 300, Loss:0.004968984483449317\n",
      "Epoch: 28, Iter: 400, Loss:0.005062550662516325\n",
      "Epoch: 28, Acc:99.08382196162047\n",
      "Epoch: 29, Iter: 100, Loss:0.0052623374119295735\n",
      "Epoch: 29, Iter: 200, Loss:0.005926205106188795\n",
      "Epoch: 29, Iter: 300, Loss:0.006053809278598949\n",
      "Epoch: 29, Iter: 400, Loss:0.005874882781826484\n",
      "Epoch: 29, Acc:99.04384328358209\n",
      "Epoch: 30, Iter: 100, Loss:0.005288427914562288\n",
      "Epoch: 30, Iter: 200, Loss:0.004308886990856641\n",
      "Epoch: 30, Iter: 300, Loss:0.005514794619066883\n",
      "Epoch: 30, Iter: 400, Loss:0.00582522652032517\n",
      "Epoch: 30, Acc:99.12213486140725\n",
      "Epoch: 31, Iter: 100, Loss:0.005118463692545239\n",
      "Epoch: 31, Iter: 200, Loss:0.004332930612653843\n",
      "Epoch: 31, Iter: 300, Loss:0.0060446632734096764\n",
      "Epoch: 31, Iter: 400, Loss:0.005293532227501591\n",
      "Epoch: 31, Acc:99.11047441364606\n",
      "Epoch: 32, Iter: 100, Loss:0.004987443854629215\n",
      "Epoch: 32, Iter: 200, Loss:0.0054387664511752155\n",
      "Epoch: 32, Iter: 300, Loss:0.004756810667583032\n",
      "Epoch: 32, Iter: 400, Loss:0.004997760038708708\n",
      "Epoch: 32, Acc:99.16044776119404\n",
      "Epoch: 33, Iter: 100, Loss:0.004295991971713505\n",
      "Epoch: 33, Iter: 200, Loss:0.004422756591077044\n",
      "Epoch: 33, Iter: 300, Loss:0.005250376922491469\n",
      "Epoch: 33, Iter: 400, Loss:0.004830635496418176\n",
      "Epoch: 33, Acc:99.19043176972282\n",
      "Epoch: 34, Iter: 100, Loss:0.004623590076321375\n",
      "Epoch: 34, Iter: 200, Loss:0.004951666591555944\n",
      "Epoch: 34, Iter: 300, Loss:0.004970387222795392\n",
      "Epoch: 34, Iter: 400, Loss:0.0052900234801269794\n",
      "Epoch: 34, Acc:99.15378464818764\n",
      "Epoch: 35, Iter: 100, Loss:0.004269217606137461\n",
      "Epoch: 35, Iter: 200, Loss:0.005517489252749012\n",
      "Epoch: 35, Iter: 300, Loss:0.00435014276915212\n",
      "Epoch: 35, Iter: 400, Loss:0.0053331268682474215\n",
      "Epoch: 35, Acc:99.2087553304904\n",
      "Epoch: 36, Iter: 100, Loss:0.004722059326572046\n",
      "Epoch: 36, Iter: 200, Loss:0.004480265104757951\n",
      "Epoch: 36, Iter: 300, Loss:0.004416230985937493\n",
      "Epoch: 36, Iter: 400, Loss:0.004224116394945633\n",
      "Epoch: 36, Acc:99.22707889125799\n",
      "Epoch: 37, Iter: 100, Loss:0.0036050778451134392\n",
      "Epoch: 37, Iter: 200, Loss:0.0034595477214303494\n",
      "Epoch: 37, Iter: 300, Loss:0.003525144723641164\n",
      "Epoch: 37, Iter: 400, Loss:0.004096440686933649\n",
      "Epoch: 37, Acc:99.35367803837953\n",
      "Epoch: 38, Iter: 100, Loss:0.00439778597541908\n",
      "Epoch: 38, Iter: 200, Loss:0.00448847964092263\n",
      "Epoch: 38, Iter: 300, Loss:0.004711040347042099\n",
      "Epoch: 38, Iter: 400, Loss:0.004008891539889445\n",
      "Epoch: 38, Acc:99.26705756929637\n",
      "Epoch: 39, Iter: 100, Loss:0.004162910453198767\n",
      "Epoch: 39, Iter: 200, Loss:0.0045243844542322735\n",
      "Epoch: 39, Iter: 300, Loss:0.0034306872485161846\n",
      "Epoch: 39, Iter: 400, Loss:0.003697483419829896\n",
      "Epoch: 39, Acc:99.29037846481876\n",
      "Epoch: 40, Iter: 100, Loss:0.003972781113912858\n",
      "Epoch: 40, Iter: 200, Loss:0.004190104657973745\n",
      "Epoch: 40, Iter: 300, Loss:0.004273510089631615\n",
      "Epoch: 40, Iter: 400, Loss:0.0044876703628098594\n",
      "Epoch: 40, Acc:99.27038912579957\n",
      "Epoch: 41, Iter: 100, Loss:0.004186692660543392\n",
      "Epoch: 41, Iter: 200, Loss:0.003601700484282029\n",
      "Epoch: 41, Iter: 300, Loss:0.0038435092220194082\n",
      "Epoch: 41, Iter: 400, Loss:0.004447252052262235\n",
      "Epoch: 41, Acc:99.29537579957356\n",
      "Epoch: 42, Iter: 100, Loss:0.0031788746199842644\n",
      "Epoch: 42, Iter: 200, Loss:0.003632274904483949\n",
      "Epoch: 42, Iter: 300, Loss:0.004144430637477772\n",
      "Epoch: 42, Iter: 400, Loss:0.0037415107462191776\n",
      "Epoch: 42, Acc:99.30203891257996\n",
      "Epoch: 43, Iter: 100, Loss:0.0032123271568575557\n",
      "Epoch: 43, Iter: 200, Loss:0.0042241776227029655\n",
      "Epoch: 43, Iter: 300, Loss:0.0038724556863893754\n",
      "Epoch: 43, Iter: 400, Loss:0.0038398609934513694\n",
      "Epoch: 43, Acc:99.33868603411514\n",
      "Epoch: 44, Iter: 100, Loss:0.003598385402793263\n",
      "Epoch: 44, Iter: 200, Loss:0.003576966982122872\n",
      "Epoch: 44, Iter: 300, Loss:0.004425941256067551\n",
      "Epoch: 44, Iter: 400, Loss:0.004435718660977588\n",
      "Epoch: 44, Acc:99.29037846481876\n",
      "Epoch: 45, Iter: 100, Loss:0.0030344645672692244\n",
      "Epoch: 45, Iter: 200, Loss:0.0028890954189512356\n",
      "Epoch: 45, Iter: 300, Loss:0.0032703306253896213\n",
      "Epoch: 45, Iter: 400, Loss:0.0036357907686449054\n",
      "Epoch: 45, Acc:99.40864872068231\n",
      "Epoch: 46, Iter: 100, Loss:0.004021390899283581\n",
      "Epoch: 46, Iter: 200, Loss:0.0037008991541858734\n",
      "Epoch: 46, Iter: 300, Loss:0.0033752754644509643\n",
      "Epoch: 46, Iter: 400, Loss:0.004371249058128976\n",
      "Epoch: 46, Acc:99.35867537313433\n",
      "Epoch: 47, Iter: 100, Loss:0.0033332750540418323\n",
      "Epoch: 47, Iter: 200, Loss:0.0027890199562844967\n",
      "Epoch: 47, Iter: 300, Loss:0.0024830953984795365\n",
      "Epoch: 47, Iter: 400, Loss:0.0034039765715535514\n",
      "Epoch: 47, Acc:99.4353011727079\n",
      "Epoch: 48, Iter: 100, Loss:0.0033923368359894067\n",
      "Epoch: 48, Iter: 200, Loss:0.0038857612695454608\n",
      "Epoch: 48, Iter: 300, Loss:0.0032222539541805024\n",
      "Epoch: 48, Iter: 400, Loss:0.00408981483603921\n",
      "Epoch: 48, Acc:99.31369936034115\n",
      "Epoch: 49, Iter: 100, Loss:0.003297327196787495\n",
      "Epoch: 49, Iter: 200, Loss:0.0034602188037585286\n",
      "Epoch: 49, Iter: 300, Loss:0.002559030595394884\n",
      "Epoch: 49, Iter: 400, Loss:0.003774589156858059\n",
      "Epoch: 49, Acc:99.40531716417911\n",
      "Epoch: 50, Iter: 100, Loss:0.003640009411687611\n",
      "Epoch: 50, Iter: 200, Loss:0.0030788821775763076\n",
      "Epoch: 50, Iter: 300, Loss:0.003464950700484113\n",
      "Epoch: 50, Iter: 400, Loss:0.003507367013194072\n",
      "Epoch: 50, Acc:99.37866471215352\n",
      "Epoch: 51, Iter: 100, Loss:0.003105376869924605\n",
      "Epoch: 51, Iter: 200, Loss:0.0034074355979193884\n",
      "Epoch: 51, Iter: 300, Loss:0.0030140853033953116\n",
      "Epoch: 51, Iter: 400, Loss:0.004144203981283113\n",
      "Epoch: 51, Acc:99.44029850746269\n",
      "Epoch: 52, Iter: 100, Loss:0.0028357802789587814\n",
      "Epoch: 52, Iter: 200, Loss:0.00319798316420324\n",
      "Epoch: 52, Iter: 300, Loss:0.004013230976115452\n",
      "Epoch: 52, Iter: 400, Loss:0.0025416926358208885\n",
      "Epoch: 52, Acc:99.45695628997868\n",
      "Epoch: 53, Iter: 100, Loss:0.0035960551853396437\n",
      "Epoch: 53, Iter: 200, Loss:0.00292450466548462\n",
      "Epoch: 53, Iter: 300, Loss:0.0031728551913944403\n",
      "Epoch: 53, Iter: 400, Loss:0.0032196815303369942\n",
      "Epoch: 53, Acc:99.46028784648188\n",
      "Epoch: 54, Iter: 100, Loss:0.003368612030427456\n",
      "Epoch: 54, Iter: 200, Loss:0.002602414412387728\n",
      "Epoch: 54, Iter: 300, Loss:0.003106173898613672\n",
      "Epoch: 54, Iter: 400, Loss:0.0033279020693088605\n",
      "Epoch: 54, Acc:99.40531716417911\n",
      "Epoch: 55, Iter: 100, Loss:0.0027507742730849016\n",
      "Epoch: 55, Iter: 200, Loss:0.0027577082181214365\n",
      "Epoch: 55, Iter: 300, Loss:0.002744433380680026\n",
      "Epoch: 55, Iter: 400, Loss:0.0037674627651317493\n",
      "Epoch: 55, Acc:99.44363006396588\n",
      "Epoch: 56, Iter: 100, Loss:0.00306653088984588\n",
      "Epoch: 56, Iter: 200, Loss:0.003607076154634563\n",
      "Epoch: 56, Iter: 300, Loss:0.002703201758718964\n",
      "Epoch: 56, Iter: 400, Loss:0.003439539321214219\n",
      "Epoch: 56, Acc:99.43696695095949\n",
      "Epoch: 57, Iter: 100, Loss:0.0021341173596971076\n",
      "Epoch: 57, Iter: 200, Loss:0.002183250553133006\n",
      "Epoch: 57, Iter: 300, Loss:0.003583836032567657\n",
      "Epoch: 57, Iter: 400, Loss:0.003122313858176431\n",
      "Epoch: 57, Acc:99.53524786780383\n",
      "Epoch: 58, Iter: 100, Loss:0.002911453839016161\n",
      "Epoch: 58, Iter: 200, Loss:0.0021176953308049964\n",
      "Epoch: 58, Iter: 300, Loss:0.0026799624757607903\n",
      "Epoch: 58, Iter: 400, Loss:0.0031947516794649084\n",
      "Epoch: 58, Acc:99.50026652452026\n",
      "Epoch: 59, Iter: 100, Loss:0.0023819822048868184\n",
      "Epoch: 59, Iter: 200, Loss:0.003334048092735113\n",
      "Epoch: 59, Iter: 300, Loss:0.0040795141679626\n",
      "Epoch: 59, Iter: 400, Loss:0.002302361664759156\n",
      "Epoch: 59, Acc:99.45362473347548\n",
      "Epoch: 60, Iter: 100, Loss:0.003428677505781767\n",
      "Epoch: 60, Iter: 200, Loss:0.0036518717094558848\n",
      "Epoch: 60, Iter: 300, Loss:0.0029121427819741442\n",
      "Epoch: 60, Iter: 400, Loss:0.003111429152457214\n",
      "Epoch: 60, Acc:99.43696695095949\n",
      "Epoch: 61, Iter: 100, Loss:0.002492477777843445\n",
      "Epoch: 61, Iter: 200, Loss:0.0027178874551338442\n",
      "Epoch: 61, Iter: 300, Loss:0.002978336044412448\n",
      "Epoch: 61, Iter: 400, Loss:0.003394377101846943\n",
      "Epoch: 61, Acc:99.48027718550107\n",
      "Epoch: 62, Iter: 100, Loss:0.0027987855850959194\n",
      "Epoch: 62, Iter: 200, Loss:0.0025572039685008534\n",
      "Epoch: 62, Iter: 300, Loss:0.0024597657580566067\n",
      "Epoch: 62, Iter: 400, Loss:0.004000348400007854\n",
      "Epoch: 62, Acc:99.50526385927505\n",
      "Epoch: 63, Iter: 100, Loss:0.002836484094036183\n",
      "Epoch: 63, Iter: 200, Loss:0.0028074959964505823\n",
      "Epoch: 63, Iter: 300, Loss:0.0033515708744158543\n",
      "Epoch: 63, Iter: 400, Loss:0.0023107641623658277\n",
      "Epoch: 63, Acc:99.51859008528784\n",
      "Epoch: 64, Iter: 100, Loss:0.003434000211320559\n",
      "Epoch: 64, Iter: 200, Loss:0.003138217899948607\n",
      "Epoch: 64, Iter: 300, Loss:0.00291419939230085\n",
      "Epoch: 64, Iter: 400, Loss:0.003559806698020786\n",
      "Epoch: 64, Acc:99.43363539445629\n",
      "Epoch: 65, Iter: 100, Loss:0.0023065280318304874\n",
      "Epoch: 65, Iter: 200, Loss:0.0023550969546165335\n",
      "Epoch: 65, Iter: 300, Loss:0.0021901313113847944\n",
      "Epoch: 65, Iter: 400, Loss:0.002822517125898583\n",
      "Epoch: 65, Acc:99.56190031982942\n",
      "Epoch: 66, Iter: 100, Loss:0.0030332395428620865\n",
      "Epoch: 66, Iter: 200, Loss:0.002425014899368696\n",
      "Epoch: 66, Iter: 300, Loss:0.002793738668106113\n",
      "Epoch: 66, Iter: 400, Loss:0.003232155733906638\n",
      "Epoch: 66, Acc:99.47527985074628\n",
      "Epoch: 67, Iter: 100, Loss:0.0022291222804172364\n",
      "Epoch: 67, Iter: 200, Loss:0.0023388496515944776\n",
      "Epoch: 67, Iter: 300, Loss:0.003006301410032063\n",
      "Epoch: 67, Iter: 400, Loss:0.002534857258942328\n",
      "Epoch: 67, Acc:99.57689232409382\n",
      "Epoch: 68, Iter: 100, Loss:0.002467186450446918\n",
      "Epoch: 68, Iter: 200, Loss:0.0018772158742215094\n",
      "Epoch: 68, Iter: 300, Loss:0.0025909565369484884\n",
      "Epoch: 68, Iter: 400, Loss:0.0025227823475775903\n",
      "Epoch: 68, Acc:99.56023454157783\n",
      "Epoch: 69, Iter: 100, Loss:0.0021889254831878252\n",
      "Epoch: 69, Iter: 200, Loss:0.00237844117230419\n",
      "Epoch: 69, Iter: 300, Loss:0.0023230445434226157\n",
      "Epoch: 69, Iter: 400, Loss:0.002927083420186941\n",
      "Epoch: 69, Acc:99.57356076759062\n",
      "Epoch: 70, Iter: 100, Loss:0.002201373935545554\n",
      "Epoch: 70, Iter: 200, Loss:0.002852515996506275\n",
      "Epoch: 70, Iter: 300, Loss:0.002276455100056957\n",
      "Epoch: 70, Iter: 400, Loss:0.002684755336571691\n",
      "Epoch: 70, Acc:99.56356609808103\n",
      "Epoch: 71, Iter: 100, Loss:0.0030622800188099364\n",
      "Epoch: 71, Iter: 200, Loss:0.002505069714257253\n",
      "Epoch: 71, Iter: 300, Loss:0.0027255820314477344\n",
      "Epoch: 71, Iter: 400, Loss:0.0028906460314468323\n",
      "Epoch: 71, Acc:99.51859008528784\n",
      "Epoch: 72, Iter: 100, Loss:0.002141720421653467\n",
      "Epoch: 72, Iter: 200, Loss:0.003312979270503032\n",
      "Epoch: 72, Iter: 300, Loss:0.0022156061142308715\n",
      "Epoch: 72, Iter: 400, Loss:0.0028977487465865147\n",
      "Epoch: 72, Acc:99.51859008528784\n",
      "Epoch: 73, Iter: 100, Loss:0.001965272305312374\n",
      "Epoch: 73, Iter: 200, Loss:0.002898672555842852\n",
      "Epoch: 73, Iter: 300, Loss:0.0029692701863009295\n",
      "Epoch: 73, Iter: 400, Loss:0.0026508716323143883\n",
      "Epoch: 73, Acc:99.56689765458422\n",
      "Epoch: 74, Iter: 100, Loss:0.0026191883148433868\n",
      "Epoch: 74, Iter: 200, Loss:0.0015655416505951643\n",
      "Epoch: 74, Iter: 300, Loss:0.0024223223357818335\n",
      "Epoch: 74, Iter: 400, Loss:0.002907109021001668\n",
      "Epoch: 74, Acc:99.56689765458422\n",
      "Epoch: 75, Iter: 100, Loss:0.00245871615329527\n",
      "Epoch: 75, Iter: 200, Loss:0.0030405492688005947\n",
      "Epoch: 75, Iter: 300, Loss:0.002200027424986087\n",
      "Epoch: 75, Iter: 400, Loss:0.0025136837565617113\n",
      "Epoch: 75, Acc:99.54524253731343\n",
      "Epoch: 76, Iter: 100, Loss:0.001472160960602855\n",
      "Epoch: 76, Iter: 200, Loss:0.002592853430976549\n",
      "Epoch: 76, Iter: 300, Loss:0.0023016226556730954\n",
      "Epoch: 76, Iter: 400, Loss:0.003455190679000349\n",
      "Epoch: 76, Acc:99.53857942430703\n",
      "Epoch: 77, Iter: 100, Loss:0.002792397624257503\n",
      "Epoch: 77, Iter: 200, Loss:0.0021831029970228654\n",
      "Epoch: 77, Iter: 300, Loss:0.0025171528517669225\n",
      "Epoch: 77, Iter: 400, Loss:0.002152685660526091\n",
      "Epoch: 77, Acc:99.52525319829424\n",
      "Epoch: 78, Iter: 100, Loss:0.0018012958261136487\n",
      "Epoch: 78, Iter: 200, Loss:0.002656169682751094\n",
      "Epoch: 78, Iter: 300, Loss:0.002890549039053393\n",
      "Epoch: 78, Iter: 400, Loss:0.0029809385307132206\n",
      "Epoch: 78, Acc:99.53857942430703\n",
      "Epoch: 79, Iter: 100, Loss:0.002257634277003996\n",
      "Epoch: 79, Iter: 200, Loss:0.0018442275627121043\n",
      "Epoch: 79, Iter: 300, Loss:0.0014695812023458516\n",
      "Epoch: 79, Iter: 400, Loss:0.0028138526021469403\n",
      "Epoch: 79, Acc:99.6102078891258\n",
      "Epoch: 80, Iter: 100, Loss:0.002975155635127998\n",
      "Epoch: 80, Iter: 200, Loss:0.00230020995518423\n",
      "Epoch: 80, Iter: 300, Loss:0.0026546675417853244\n",
      "Epoch: 80, Iter: 400, Loss:0.0015871372140411819\n",
      "Epoch: 80, Acc:99.54191098081023\n",
      "Epoch: 81, Iter: 100, Loss:0.002125971409904737\n",
      "Epoch: 81, Iter: 200, Loss:0.002928602079096844\n",
      "Epoch: 81, Iter: 300, Loss:0.0024426744553073844\n",
      "Epoch: 81, Iter: 400, Loss:0.002364366163906362\n",
      "Epoch: 81, Acc:99.55523720682302\n",
      "Epoch: 82, Iter: 100, Loss:0.00257217201169333\n",
      "Epoch: 82, Iter: 200, Loss:0.0020981335809314326\n",
      "Epoch: 82, Iter: 300, Loss:0.0020535612189334315\n",
      "Epoch: 82, Iter: 400, Loss:0.0019826758625931533\n",
      "Epoch: 82, Acc:99.6068763326226\n",
      "Epoch: 83, Iter: 100, Loss:0.0015536624558038139\n",
      "Epoch: 83, Iter: 200, Loss:0.002322589997285312\n",
      "Epoch: 83, Iter: 300, Loss:0.002580089289493966\n",
      "Epoch: 83, Iter: 400, Loss:0.002155268064889087\n",
      "Epoch: 83, Acc:99.5918843283582\n",
      "Epoch: 84, Iter: 100, Loss:0.002228203874358387\n",
      "Epoch: 84, Iter: 200, Loss:0.002289819446282396\n",
      "Epoch: 84, Iter: 300, Loss:0.002266036414830853\n",
      "Epoch: 84, Iter: 400, Loss:0.003041094427045657\n",
      "Epoch: 84, Acc:99.53025053304904\n",
      "Epoch: 85, Iter: 100, Loss:0.002131354316871967\n",
      "Epoch: 85, Iter: 200, Loss:0.0015190093987695833\n",
      "Epoch: 85, Iter: 300, Loss:0.0014642152858566422\n",
      "Epoch: 85, Iter: 400, Loss:0.002474007065493444\n",
      "Epoch: 85, Acc:99.65851545842217\n",
      "Epoch: 86, Iter: 100, Loss:0.002041224863717525\n",
      "Epoch: 86, Iter: 200, Loss:0.0017629991687495691\n",
      "Epoch: 86, Iter: 300, Loss:0.001662118599575975\n",
      "Epoch: 86, Iter: 400, Loss:0.0022542940467495027\n",
      "Epoch: 86, Acc:99.62519989339019\n",
      "Epoch: 87, Iter: 100, Loss:0.0019667668478668427\n",
      "Epoch: 87, Iter: 200, Loss:0.002527559129732238\n",
      "Epoch: 87, Iter: 300, Loss:0.0019223470850553521\n",
      "Epoch: 87, Iter: 400, Loss:0.0016307860271426724\n",
      "Epoch: 87, Acc:99.6035447761194\n",
      "Epoch: 88, Iter: 100, Loss:0.0015297048680709803\n",
      "Epoch: 88, Iter: 200, Loss:0.0023573027706944812\n",
      "Epoch: 88, Iter: 300, Loss:0.002026645969765793\n",
      "Epoch: 88, Iter: 400, Loss:0.0019230299350271411\n",
      "Epoch: 88, Acc:99.65018656716418\n",
      "Epoch: 89, Iter: 100, Loss:0.00235014980521623\n",
      "Epoch: 89, Iter: 200, Loss:0.0019048286329417217\n",
      "Epoch: 89, Iter: 300, Loss:0.0024141430240328006\n",
      "Epoch: 89, Iter: 400, Loss:0.0020608777208673233\n",
      "Epoch: 89, Acc:99.6118736673774\n",
      "Epoch: 90, Iter: 100, Loss:0.0021945843450581854\n",
      "Epoch: 90, Iter: 200, Loss:0.002303414594555554\n",
      "Epoch: 90, Iter: 300, Loss:0.0023242352859221094\n",
      "Epoch: 90, Iter: 400, Loss:0.0030696840365670485\n",
      "Epoch: 90, Acc:99.58022388059702\n",
      "Epoch: 91, Iter: 100, Loss:0.002090141414010625\n",
      "Epoch: 91, Iter: 200, Loss:0.0023849064613995787\n",
      "Epoch: 91, Iter: 300, Loss:0.0020095381979873504\n",
      "Epoch: 91, Iter: 400, Loss:0.0025105065386767174\n",
      "Epoch: 91, Acc:99.6068763326226\n",
      "Epoch: 92, Iter: 100, Loss:0.0020736251427888324\n",
      "Epoch: 92, Iter: 200, Loss:0.00211809276475515\n",
      "Epoch: 92, Iter: 300, Loss:0.0027033703635384178\n",
      "Epoch: 92, Iter: 400, Loss:0.0023067300212877328\n",
      "Epoch: 92, Acc:99.57689232409382\n",
      "Epoch: 93, Iter: 100, Loss:0.0017458872650959727\n",
      "Epoch: 93, Iter: 200, Loss:0.0013870480561114873\n",
      "Epoch: 93, Iter: 300, Loss:0.002548334723162124\n",
      "Epoch: 93, Iter: 400, Loss:0.0024423981872898565\n",
      "Epoch: 93, Acc:99.6168710021322\n",
      "Epoch: 94, Iter: 100, Loss:0.0016464189333872978\n",
      "Epoch: 94, Iter: 200, Loss:0.002002512879784096\n",
      "Epoch: 94, Iter: 300, Loss:0.0020626103014946837\n",
      "Epoch: 94, Iter: 400, Loss:0.0018476822573544164\n",
      "Epoch: 94, Acc:99.66851012793177\n",
      "Epoch: 95, Iter: 100, Loss:0.0020698720772280546\n",
      "Epoch: 95, Iter: 200, Loss:0.0018538819519363081\n",
      "Epoch: 95, Iter: 300, Loss:0.0025392063520550887\n",
      "Epoch: 95, Iter: 400, Loss:0.0019659714843016187\n",
      "Epoch: 95, Acc:99.65351812366738\n",
      "Epoch: 96, Iter: 100, Loss:0.0025358741514481305\n",
      "Epoch: 96, Iter: 200, Loss:0.001516553879707311\n",
      "Epoch: 96, Iter: 300, Loss:0.0028759564264309602\n",
      "Epoch: 96, Iter: 400, Loss:0.0024410426771154813\n",
      "Epoch: 96, Acc:99.57689232409382\n",
      "Epoch: 97, Iter: 100, Loss:0.0013908734586688557\n",
      "Epoch: 97, Iter: 200, Loss:0.0024438103591005052\n",
      "Epoch: 97, Iter: 300, Loss:0.0016115973331387898\n",
      "Epoch: 97, Iter: 400, Loss:0.0016345422865928652\n",
      "Epoch: 97, Acc:99.67517324093816\n",
      "Epoch: 98, Iter: 100, Loss:0.0017895716680166648\n",
      "Epoch: 98, Iter: 200, Loss:0.001969290053952726\n",
      "Epoch: 98, Iter: 300, Loss:0.002584278515746955\n",
      "Epoch: 98, Iter: 400, Loss:0.0013903464468172206\n",
      "Epoch: 98, Acc:99.62853144989339\n",
      "Epoch: 99, Iter: 100, Loss:0.001488089568195378\n",
      "Epoch: 99, Iter: 200, Loss:0.0021846774784913376\n",
      "Epoch: 99, Iter: 300, Loss:0.0020926576612558443\n",
      "Epoch: 99, Iter: 400, Loss:0.001834572299411133\n",
      "Epoch: 99, Acc:99.630197228145\n",
      "Epoch: 100, Iter: 100, Loss:0.0015488561140241791\n",
      "Epoch: 100, Iter: 200, Loss:0.0021223196932208983\n",
      "Epoch: 100, Iter: 300, Loss:0.0023807629749964753\n",
      "Epoch: 100, Iter: 400, Loss:0.00214203176980859\n",
      "Epoch: 100, Acc:99.64685501066099\n"
     ]
    }
   ],
   "source": [
    "batch_size=128 # 학습할 때 얼마나 많은 데이터를 이용할 것인가 \n",
    "steps_per_epoch=len(train_loader) # 한 epoch 당 스텝 수 (batch_size크기의 데이터 개수)\n",
    "\n",
    "# epoch 수는 50\n",
    "for epoch in range(100):\n",
    "    running_loss=0.0 # 초기 누적 오차 = 0 \n",
    "    batch_acc_list=[] # batch 별 accuracy list\n",
    "\n",
    "    # step (steps_per_epoch:469)\n",
    "    for i, data in enumerate(train_loader,0):\n",
    "        # 데이터 입력\n",
    "        inputs, labels=data\n",
    "        inputs=inputs.to(device)\n",
    "        labels=labels.to(device)\n",
    "        # Gradient -> 0\n",
    "        optimizer.zero_grad()\n",
    "        # 순전파+역전파+최적화 \n",
    "        outputs=mynet(inputs)\n",
    "        loss=criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # 누적 오차 \n",
    "        running_loss +=loss.item()\n",
    "\n",
    "        # batch_accuracy 계산 (한 스텝마다 accuracy 저장)\n",
    "        _,predicted=torch.max(outputs.data,1)\n",
    "        correct=(predicted==labels).sum().item()\n",
    "        batch_acc = correct/batch_size * 100\n",
    "        batch_acc_list.append(batch_acc)\n",
    "\n",
    "        if i % 100 == 99:\n",
    "            print('Epoch: {}, Iter: {}, Loss:{}'.format(epoch+1,i+1,running_loss/steps_per_epoch))\n",
    "            running_loss=0.0\n",
    "\n",
    "    # epoch마다 accuracy 출력\n",
    "    epoch_acc=np.mean(batch_acc_list) # batch_accuracy_list의 평균으로 계산 (전체 데이터를 기준)\n",
    "    print('Epoch: {}, Acc:{}'.format(epoch+1,epoch_acc))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.72\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "total=0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels=data\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs=mynet(images)\n",
    "        _,predicted=torch.max(outputs.data,1)\n",
    "        total+=labels.size(0)\n",
    "        correct+=(predicted==labels).sum().item()\n",
    "\n",
    "print(correct/total*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
